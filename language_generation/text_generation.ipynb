{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a2eb27",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center; font-size: 30px;\"><b>Text Generation</b></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af10e4c",
   "metadata": {},
   "source": [
    "# Long Short-Term Memory Networks\n",
    "\n",
    "Long short-term memory networks (LSTMs) are a specialized type of recurrent neural network (RNN) designed to capture long-range dependencies in sequential data. They are widely used in natural language processing (NLP) for tasks such as machine translation, speech generation, summarization, and dialogue systems.\n",
    "\n",
    "## Information Persistence and Neural Networks\n",
    "\n",
    "Human language relies on persistent structures: grammar rules, shared vocabulary, and the ability to interpret each word in context. As you read, earlier sentences influence your understanding of later ones ‚Äî demonstrating long-term information retention.\n",
    "\n",
    "Neural networks, inspired by the brain, initially struggled with such temporal relationships. Early models like perceptrons performed static transformations without memory, limiting their effectiveness on tasks requiring sequential reasoning.\n",
    "\n",
    "## Deep Neural Networks\n",
    "\n",
    "Modern hardware enabled deeper architectures such as:\n",
    "\n",
    "* **MLPs (Multi-Layer Perceptrons):** Stacks of perceptrons, effective for simple input‚Äìoutput transformations.\n",
    "* **CNNs (Convolutional Neural Networks):** Specialized for images, using filters that scan across spatial dimensions.\n",
    "* **RNNs (Recurrent Neural Networks):** Designed for sequences, where each output depends on previous inputs.\n",
    "\n",
    "RNNs ‚Äúunroll‚Äù across time, producing hidden states that propagate contextual information forward.\n",
    "\n",
    "## The Long-Term Dependency Problem\n",
    "\n",
    "Standard RNNs struggle with long sequences due to vanishing and exploding gradients. They perform well when the relevant context is close to the prediction target (e.g., completing ‚ÄúThe grass is always ___‚Äù ‚Üí ‚Äúgreener‚Äù).\n",
    "\n",
    "However, in sentences requiring distant context ‚Äî\n",
    "*‚ÄúIt is winter‚Ä¶ The grass is always ___.‚Äù* ‚Üí ‚Äúbrown‚Äù ‚Äî\n",
    "standard RNNs fail to preserve the necessary information across many timesteps.\n",
    "\n",
    "This challenge is known as the **long-term dependency problem**.\n",
    "\n",
    "## Long Short-Term Memory (LSTM) Networks\n",
    "\n",
    "LSTMs were introduced to address these limitations. While maintaining the chain structure of RNNs, LSTMs replace the simple recurrent unit with a more sophisticated cell composed of multiple interacting components.\n",
    "\n",
    "An LSTM cell processes input using **four internal operations** controlled by gates:\n",
    "\n",
    "1. **Forget gate:** Determines how much of the previous cell state to keep.\n",
    "2. **Input gate:** Regulates how much new information to write to the cell.\n",
    "3. **Candidate state:** Proposes new content to add.\n",
    "4. **Output gate:** Controls how much of the updated cell state forms the new hidden state.\n",
    "\n",
    "## Cell State and Hidden State\n",
    "\n",
    "The LSTM maintains two vector states:\n",
    "\n",
    "* **Cell state** $c_t$: acts as long-term memory, carrying information across many timesteps.\n",
    "* **Hidden state** $h_t$: short-term output used for predictions and passed to subsequent layers.\n",
    "\n",
    "The core update equations (simplified) are:\n",
    "\n",
    "$$\n",
    "f_t = \\sigma(W_f[x_t, h_{t-1}] + b_f)\n",
    "$$\n",
    "\n",
    "$$\n",
    "i_t = \\sigma(W_i[x_t, h_{t-1}] + b_i)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\tilde{c}*t = \\tanh(W_c[x_t, h*{t-1}] + b_c)\n",
    "$$\n",
    "\n",
    "$$\n",
    "c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t\n",
    "$$\n",
    "\n",
    "$$\n",
    "o_t = \\sigma(W_o[x_t, h_{t-1}] + b_o)\n",
    "$$\n",
    "\n",
    "$$\n",
    "h_t = o_t \\odot \\tanh(c_t)\n",
    "$$\n",
    "\n",
    "These gating mechanisms allow LSTMs to preserve important information and discard irrelevant details as sequences evolve.\n",
    "\n",
    "## Why LSTMs Matter\n",
    "\n",
    "By blending persistent memory with selective updates, LSTMs excel at:\n",
    "\n",
    "* Capturing long-term patterns\n",
    "* Modeling contextual relationships over extended text\n",
    "* Generating coherent sequences\n",
    "* Handling variable-length inputs\n",
    "\n",
    "They remain foundational components in many deep learning systems, even as newer models (like Transformers) gain prominence.\n",
    "\n",
    "LSTMs provide a robust solution to the limitations of traditional RNNs, enabling machines to leverage distant context much like humans do when interpreting language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ff434",
   "metadata": {},
   "source": [
    "# Introduction to seq2seq\n",
    "\n",
    "Sequence-to-sequence (seq2seq) models extend the power of LSTMs by organizing them into a larger **encoder‚Äìdecoder** architecture capable of generating entire sequences of text. While LSTMs handle temporal dependencies within a sequence, seq2seq models specialize in transforming one sequence into another ‚Äî often of different length and structure.\n",
    "\n",
    "## Where seq2seq Models Are Used\n",
    "\n",
    "Seq2seq architectures power many modern NLP systems, including:\n",
    "\n",
    "* Machine translation (e.g., Google Translate)\n",
    "* Automatic text summarization\n",
    "* Chatbots and conversational agents\n",
    "* Named Entity Recognition (NER)\n",
    "* Speech recognition and transcription\n",
    "\n",
    "These applications require understanding an input sequence and producing a coherent, structured output sequence.\n",
    "\n",
    "## Encoder‚ÄìDecoder Structure\n",
    "\n",
    "A seq2seq network is composed of two recurrent components:\n",
    "\n",
    "### **1. Encoder**\n",
    "\n",
    "* Accepts the input sequence (text, audio, or video).\n",
    "* Processes each element step by step through an RNN (often an LSTM).\n",
    "* Discards the encoder‚Äôs final output matrix but **retains its final hidden state**.\n",
    "* This hidden state becomes a compressed representation ‚Äî a fixed-length vector capturing the meaning of the entire input sequence.\n",
    "\n",
    "### **2. Decoder**\n",
    "\n",
    "* Starts with the encoder‚Äôs final state as its initial state.\n",
    "* Generates tokens one at a time to form the output sequence.\n",
    "* During training, uses **teacher forcing**, where the correct previous token is supplied to help the model learn the next-token prediction more efficiently.\n",
    "\n",
    "Teacher forcing trains the decoder to predict the next character or word in the target output sequence, given all previous correct tokens.\n",
    "\n",
    "## Why seq2seq Matters\n",
    "\n",
    "Seq2seq models brought coherence and fluency to early neural text-generation systems by enabling networks to read an entire input, compress it into memory, and then reconstruct or transform it into a new sequence. They laid the groundwork for modern architectures such as attention-based seq2seq models and the Transformer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f3c4f",
   "metadata": {},
   "source": [
    "# Preprocessing for seq2seq\n",
    "\n",
    "Before building a sequence-to-sequence (seq2seq) model with TensorFlow and Keras, the first major step is **preprocessing the text data**. This ensures that both the encoder (English) and decoder (Spanish) can operate on clean, tokenized sequences with appropriate vocabulary and structure.\n",
    "\n",
    "## Using TensorFlow and Keras\n",
    "\n",
    "Keras is accessed directly from TensorFlow:\n",
    "\n",
    "```python\n",
    "from tensorflow import keras\n",
    "```\n",
    "\n",
    "Keras provides high-level components for model building, making it well-suited for seq2seq architectures.\n",
    "\n",
    "## What We Need to Prepare\n",
    "\n",
    "To train even a small English-to-Spanish translator, preprocessing must produce several key components:\n",
    "\n",
    "### **1. Vocabulary Sets**\n",
    "\n",
    "For both languages, we need:\n",
    "\n",
    "* A set of all unique input tokens for English\n",
    "* A set of all unique target tokens for Spanish\n",
    "\n",
    "These vocabularies determine the dimensionality of the encoder and decoder input layers.\n",
    "\n",
    "### **2. Token Counts**\n",
    "\n",
    "For each language:\n",
    "\n",
    "* The total number of unique tokens\n",
    "* Used to define embedding sizes, one-hot encodings, or output layer dimensions\n",
    "\n",
    "### **3. Maximum Sentence Lengths**\n",
    "\n",
    "Models require fixed-length input sequences.\n",
    "We compute:\n",
    "\n",
    "* Maximum input sentence length (English)\n",
    "* Maximum target sentence length (Spanish)\n",
    "\n",
    "These values control padding and ensure uniform tensor shapes.\n",
    "\n",
    "## Marking Start and End of Target Sequences\n",
    "\n",
    "Seq2seq decoders must know:\n",
    "\n",
    "* When to **start** generating text\n",
    "* When to **stop** generating text\n",
    "\n",
    "To achieve this, each target sentence is wrapped with special tokens:\n",
    "\n",
    "* Prepend `<START>`\n",
    "* Append `<END>`\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Estoy feliz.\n",
    "‚Üí <START> Estoy feliz. <END>\n",
    "```\n",
    "\n",
    "This teaches the decoder to begin generation at `<START>` and stop once it predicts `<END>`.\n",
    "\n",
    "## Noise Removal Considerations\n",
    "\n",
    "Depending on your goal, you may normalize:\n",
    "\n",
    "* Casing\n",
    "* Punctuation\n",
    "* Special characters\n",
    "\n",
    "For many applications, these details are not critical, and simplifying the text can improve model performance and reduce vocabulary size.\n",
    "\n",
    "## Before Continuing\n",
    "\n",
    "You should examine the provided `script.py` and read each line closely. Understanding how text is loaded, tokenized, padded, and indexed will help you modify or extend the model later‚Äîfor example, improving translation quality or adapting the system to new languages.\n",
    "\n",
    "This preprocessing pipeline sets the foundation for building the encoder‚Äìdecoder architecture that powers seq2seq translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a226672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"We'll see.\\tDespu√©s veremos.\", \"We'll see.\\tYa veremos.\", \"We'll try.\\tLo intentaremos.\", \"We've won!\\t¬°Hemos ganado!\", 'Well done.\\tBien hecho.', \"What's up?\\t¬øQu√© hay?\", 'Who cares?\\t¬øA qui√©n le importa?', 'Who drove?\\t¬øQui√©n condujo?', 'Who drove?\\t¬øQui√©n conduc√≠a?', 'Who is he?\\t¬øQui√©n es √©l?', 'Who is it?\\t¬øQui√©n es?']\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import required libraries and load the span-eng.txt file\n",
    "from tensorflow import keras\n",
    "import re\n",
    "\n",
    "data_path = \"utils/span-eng.txt\"\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "print(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59ab657",
   "metadata": {},
   "source": [
    "**What the code does:**\n",
    "\n",
    "Opens the translation file in read mode, using UTF-8 encoding so that accented characters like √°, √©, √±, ¬ø, ¬° load correctly. The file handle is stored in f. It creates a list of strings which are split at the character \"\\n\", which represents the new line,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f09b7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Initialize empty lists for sentences and vocab sets\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70bc23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Process each line, looping ove the lines list\n",
    "for line in lines:\n",
    "    # Example: line 1 = \"We'll see.\\tDespu√©s veremos.\"\n",
    "    input_doc, target_doc = line.split('\\t')\n",
    "    '''\n",
    "    What the code does:\n",
    "    Splits the translation pair into:\n",
    "    - input_doc ‚Üí the English sentence (before the tab, represented by '\\t', which is none other than a space in the text)\n",
    "    - target_doc ‚Üí the Spanish sentence (after the tab)\n",
    "    This is the fundamental step that separates the two languages for encoder/decoder processing.\n",
    "    '''\n",
    "    # Example input_doc: \"We'll see.\"\n",
    "    input_docs.append(input_doc)\n",
    "    # Appends \"We'll see.\"toinput_docs\n",
    "    \n",
    "    # Example target_doc: \"Despu√©s veremos.\"\n",
    "    # Split punctuation: \"Despu√©s veremos .\" for example\n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    '''\n",
    "    What the code does:\n",
    "    Uses a regular expression to separate punctuation from words, ensuring every token (words and punctuation marks) becomes an individual element when later split.\n",
    "    This helps the model treat the period \".\" as its own token instead of attaching it to the last word.\n",
    "    '''\n",
    "    # Add start/end tokens:\n",
    "    # \"<START> Despu√©s veremos . <END>\"\n",
    "    target_doc = \"<START> \" + target_doc + \" <END>\"\n",
    "    target_docs.append(target_doc)\n",
    "\n",
    "    # Example tokens from input_doc: [\"We\", \"'\", \"ll\", \"see\", \".\"]\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "        input_tokens.add(token)\n",
    "\n",
    "    # Example tokens from target_doc: [\"<START>\", \"Despu√©s\", \"veremos\", \".\", \"<END>\"]\n",
    "    for token in target_doc.split():\n",
    "        target_tokens.add(token)\n",
    "        '''\n",
    "        What the code does:\n",
    "        Loops through every token (word or punctuation mark) in the English sentence.\n",
    "        The regex ensures punctuation like \".\" becomes its own token, which helps build a clean, consistent vocabulary for the encoder.\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3122b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Sort vocabularies\n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "# Step 5: Count vocabulary sizes\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "# Step 6: Compute max sequence lengths\n",
    "try:\n",
    "    max_encoder_seq_length = max(\n",
    "        len(re.findall(r\"[\\w']+|[^\\s\\w]\", doc)) for doc in input_docs\n",
    "    )\n",
    "    max_decoder_seq_length = max(\n",
    "        len(re.findall(r\"[\\w']+|[^\\s\\w]\", doc)) for doc in target_docs\n",
    "    )\n",
    "except ValueError:\n",
    "    max_encoder_seq_length = 0\n",
    "    max_decoder_seq_length = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef2e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"We'll see.\", \"We'll see.\", \"We'll try.\", \"We've won!\", 'Well done.', \"What's up?\", 'Who cares?', 'Who drove?', 'Who drove?', 'Who is he?', 'Who is it?']\n",
      "['<START> Despu√©s veremos . <END>', '<START> Ya veremos . <END>', '<START> Lo intentaremos . <END>', '<START> ¬° Hemos ganado ! <END>', '<START> Bien hecho . <END>', '<START> ¬ø Qu√© hay ? <END>', '<START> ¬ø A qui√©n le importa ? <END>', '<START> ¬ø Qui√©n condujo ? <END>', '<START> ¬ø Qui√©n conduc√≠a ? <END>', '<START> ¬ø Qui√©n es √©l ? <END>', '<START> ¬ø Qui√©n es ? <END>']\n",
      "['!', '.', '?', \"We'll\", \"We've\", 'Well', \"What's\", 'Who', 'cares', 'done', 'drove', 'he', 'is', 'it', 'see', 'try', 'up', 'won']\n",
      "['!', '.', '<END>', '<START>', '?', 'A', 'Bien', 'Despu√©s', 'Hemos', 'Lo', 'Qui√©n', 'Qu√©', 'Ya', 'conduc√≠a', 'condujo', 'es', 'ganado', 'hay', 'hecho', 'importa', 'intentaremos', 'le', 'qui√©n', 'veremos', '¬°', '¬ø', '√©l']\n"
     ]
    }
   ],
   "source": [
    "print(input_docs)\n",
    "print(target_docs)\n",
    "print(input_tokens)\n",
    "print(target_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30f73728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "27\n",
      "4\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(num_encoder_tokens) #> same as lenght input_tokens\n",
    "print(num_decoder_tokens) #> same as lenght taeget_tokens\n",
    "print(max_encoder_seq_length)\n",
    "print(max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ded1872",
   "metadata": {},
   "source": [
    "## Why the Encoder Gives Length 4 but the Decoder Gives Length 12\n",
    "\n",
    "### (And exactly *what question* the regex ‚Äúasks‚Äù to split `<START>` into 3 tokens)\n",
    "\n",
    "The key difference comes from how the regex:\n",
    "\n",
    "```\n",
    "[\\w']+|[^\\s\\w]\n",
    "```\n",
    "\n",
    "**interprets characters**. Let‚Äôs break that down clearly.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Encoder sentences ‚Üí clean words + punctuation\n",
    "\n",
    "Example encoder sentence:\n",
    "\n",
    "```\n",
    "Who is he?\n",
    "```\n",
    "\n",
    "The regex asks:\n",
    "\n",
    "### **A) ‚ÄúIs this one or more word characters or apostrophes?‚Äù**\n",
    "\n",
    "‚Üí `[\\w']+`\n",
    "Matches:\n",
    "\n",
    "* `Who`\n",
    "* `is`\n",
    "* `he`\n",
    "\n",
    "### **B) ‚ÄúIf not, is it a single character that is NOT whitespace and NOT a word character?‚Äù**\n",
    "\n",
    "‚Üí `[^\\s\\w]`\n",
    "Matches:\n",
    "\n",
    "* `?`\n",
    "\n",
    "So the regex produces:\n",
    "\n",
    "```\n",
    "[\"Who\", \"is\", \"he\", \"?\"]   ‚Üí length = 4\n",
    "```\n",
    "\n",
    "This is why:\n",
    "\n",
    "```\n",
    "max_encoder_seq_length = 4\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Decoder sentences ‚Üí include `<START>` and `<END>` which the regex **cannot** treat as single tokens\n",
    "\n",
    "Take this decoder sentence:\n",
    "\n",
    "```\n",
    "<START> ¬ø A qui√©n le importa ? <END>\n",
    "```\n",
    "\n",
    "Now the regex checks each character and asks the same questions:\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùó How the regex splits `<START>` into 3 tokens\n",
    "\n",
    "### **Character-by-character interrogation:**\n",
    "\n",
    "1. `\"<\"`\n",
    "\n",
    "   * Is it `[\\w']+`? ‚Üí **No** (it‚Äôs not a word or apostrophe)\n",
    "   * Is it `[^\\s\\w]` (not whitespace, not a word)? ‚Üí **Yes**\n",
    "     ‚Üí Token: `\"<\"`\n",
    "\n",
    "2. `\"START\"`\n",
    "\n",
    "   * Are these word characters? ‚Üí **Yes**\n",
    "     ‚Üí Token: `\"START\"`\n",
    "\n",
    "3. `\">\"`\n",
    "\n",
    "   * Is it a word? ‚Üí **No**\n",
    "   * Is it non-space & non-word? ‚Üí **Yes**\n",
    "     ‚Üí Token: `\">\"`\n",
    "\n",
    "### So the regex produces:\n",
    "\n",
    "```\n",
    "\"<START>\" ‚Üí [\"<\", \"START\", \">\"]   # 3 tokens\n",
    "```\n",
    "\n",
    "Same logic applies to `<END>`:\n",
    "\n",
    "```\n",
    "\"<END>\" ‚Üí [\"<\", \"END\", \">\"]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ùó How the rest of the Spanish sentence is processed\n",
    "\n",
    "`¬ø A qui√©n le importa ?` becomes:\n",
    "\n",
    "```\n",
    "\"¬ø\"      ‚Üí punctuation token\n",
    "\"A\"      ‚Üí word token\n",
    "\"qui√©n\"  ‚Üí word token\n",
    "\"le\"     ‚Üí word token\n",
    "\"importa\"‚Üí word token\n",
    "\"?\"      ‚Üí punctuation token\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Final token list the regex produces for the decoder‚Äôs longest sentence\n",
    "\n",
    "```\n",
    "[\n",
    "  '<', 'START', '>',          # <START>\n",
    "  '¬ø', 'A', 'qui√©n', 'le', 'importa', '?',   # Spanish content\n",
    "  '<', 'END', '>'             # <END>\n",
    "]\n",
    "```\n",
    "\n",
    "Count them:\n",
    "\n",
    "```\n",
    "3 (START) + 6 (Spanish) + 3 (END) = 12 tokens\n",
    "```\n",
    "\n",
    "So:\n",
    "\n",
    "```\n",
    "max_decoder_seq_length = 12\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üî• Final Summary\n",
    "\n",
    "* The encoder has no `<...>` tokens ‚Üí clean tokenization ‚Üí max length is **4**.\n",
    "* The decoder includes `<START>` and `<END>` ‚Üí regex splits them into **\"<\"**, **\"START\"**, **\">\"**.\n",
    "* The regex ‚Äúasks‚Äù two questions for each match attempt:\n",
    "\n",
    "  1. **Is this one or more word characters/apostrophes?**\n",
    "  2. **If not, is it a single non-space, non-word character?**\n",
    "* Because `<` and `>` are non-word characters, and ‚ÄúSTART‚Äù is a word, the regex produces **three tokens** per marker.\n",
    "\n",
    "That is the entire reason why the decoder sequence length jumps to **12**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe203a",
   "metadata": {},
   "source": [
    "# Training Setup (part 1)\n",
    "\n",
    "To train a seq2seq model, each sentence must be transformed into a numerical format that Keras and TensorFlow can understand. This is done using **one-hot vectors** within 3-dimensional matrices representing all training samples.\n",
    "\n",
    "## What Is a One-Hot Vector?\n",
    "\n",
    "A one-hot vector represents a single token using zeros everywhere except the index of that token.\n",
    "Given the vocabulary:\n",
    "\n",
    "```\n",
    "[\"the\", \"dog\", \"licked\", \"me\"]\n",
    "```\n",
    "\n",
    "The one-hot vector for **‚Äúdog‚Äù** is:\n",
    "\n",
    "```\n",
    "[0, 1, 0, 0]\n",
    "```\n",
    "\n",
    "Each token in the sentence gets its own one-hot vector.\n",
    "\n",
    "## Why We Need Feature Dictionaries\n",
    "\n",
    "Before vectorizing the data, we must map each token to a numerical index.\n",
    "We create four dictionaries:\n",
    "\n",
    "* **English features dictionary:** maps English tokens ‚Üí indices\n",
    "* **Spanish features dictionary:** maps Spanish tokens ‚Üí indices\n",
    "* **Reverse English dictionary:** maps indices ‚Üí English tokens\n",
    "* **Reverse Spanish dictionary:** maps indices ‚Üí Spanish tokens\n",
    "\n",
    "These mappings allow us to convert words into vectors, and later convert model predictions back into words.\n",
    "\n",
    "## Building the Encoder Input Matrix\n",
    "\n",
    "We initialize the encoder input matrix using NumPy:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "```\n",
    "\n",
    "## Breaking Down the Encoder Matrix\n",
    "\n",
    "The `encoder_input_data` matrix is filled with zeros initially. Its dimensions are:\n",
    "\n",
    "1. **Number of documents**\n",
    "   Each English sentence is one training example.\n",
    "\n",
    "2. **Maximum encoder sequence length**\n",
    "   All English sentences are padded or shortened to match this length.\n",
    "\n",
    "3. **Number of encoder tokens**\n",
    "   The size of the English vocabulary, determining the length of each one-hot vector.\n",
    "\n",
    "## Why Use Float32?\n",
    "\n",
    "Setting `dtype='float32'` ensures efficient computation on modern hardware, especially GPUs. Although one-hot vectors contain only 0s and 1s, float32 allows smooth integration with TensorFlow operations.\n",
    "\n",
    "This setup prepares the encoder data for the process of converting tokens into one-hot vectors that feed the LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a63907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 11\n",
      "Number of unique input tokens: 18\n",
      "Number of unique output tokens: 27\n",
      "Max sequence length for inputs: 4\n",
      "Max sequence length for outputs: 12\n",
      "\n",
      "Here's the first item in the encoder input matrix:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "The number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import required libraries and preprocessed data\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Inspect basic dataset statistics (number of samples, tokens, and max lengths)\n",
    "print('Number of samples:', len(input_docs))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "# Step 3: Build the input features dictionary (token -> index) for English\n",
    "# Example: if input_tokens = [\"We'll\", \"see\", \".\"]\n",
    "# input_features_dict might be {\"We'll\": 0, \"see\": 1, \".\": 2}\n",
    "input_features_dict = dict(\n",
    "    (token, i) for i, token in enumerate(input_tokens)\n",
    ")\n",
    "\n",
    "# Step 4: Build the target features dictionary (token -> index) for Spanish\n",
    "# Example: if target_tokens = [\"<START>\", \"Despu√©s\", \"veremos\", \".\", \"<END>\"]\n",
    "# target_features_dict might be {\"<START>\": 0, \"Despu√©s\": 1, \"veremos\": 2, \".\": 3, \"<END>\": 4}\n",
    "target_features_dict = dict(\n",
    "    (token, i) for i, token in enumerate(target_tokens)\n",
    ")\n",
    "\n",
    "# Step 5: Build the reverse input features dictionary (index -> token) for English\n",
    "# This lets us go from model predictions (indices) back to words.\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items()\n",
    ")\n",
    "\n",
    "# Step 6: Build the reverse target features dictionary (index -> token) for Spanish\n",
    "# Same idea as above, but for the decoder language.\n",
    "reverse_target_features_dict = dict(\n",
    "    (i, token) for token, i in target_features_dict.items()\n",
    ")\n",
    "\n",
    "# Step 7: Create the encoder input matrix of zeros (one-hot containers for English)\n",
    "# Shape: (num_samples, max_encoder_seq_length, num_encoder_tokens)\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# Step 8: Create the decoder input matrix of zeros (one-hot containers for Spanish decoder input)\n",
    "# Shape: (num_samples, max_decoder_seq_length, num_decoder_tokens)\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# Step 9: Create the decoder target matrix of zeros (expected Spanish outputs)\n",
    "# Shape: (num_samples, max_decoder_seq_length, num_decoder_tokens)\n",
    "# For now, decoder_input_data and decoder_target_data will be identical shells.\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32'\n",
    ")\n",
    "\n",
    "# Step 10: Print a quick sanity check for the encoder input matrix\n",
    "print(\n",
    "    \"\\nHere's the first item in the encoder input matrix:\\n\",\n",
    "    encoder_input_data[0],\n",
    "    \"\\n\\nThe number of columns should match the number of unique input tokens \"\n",
    "    \"and the number of rows should match the maximum sequence length for input sentences.\"\n",
    ")\n",
    "\n",
    "# Step 11: (Placeholder comments for later) Build out decoder_input_data and decoder_target_data values\n",
    "# In the next step, you will fill encoder_input_data, decoder_input_data,\n",
    "# and decoder_target_data with actual one-hot encodings based on the\n",
    "# feature dictionaries and the tokenized sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45066e9",
   "metadata": {},
   "source": [
    "## Key Insights: How the Three Seq2Seq Matrices Work and How They Are Built\n",
    "\n",
    "### 1. **`encoder_input_data`** ‚Äî *What the encoder reads*\n",
    "\n",
    "* **Shape:**\n",
    "  `(#samples, max_encoder_seq_length, num_encoder_tokens)`\n",
    "* **Represents:**\n",
    "  The **English input sentences**, converted into one-hot vectors.\n",
    "* **How it is filled:**\n",
    "  For each English sentence, each token position becomes a one-hot vector over the **encoder vocabulary**.\n",
    "* **Purpose:**\n",
    "  Feeds the encoder with the sequence it must **encode into a final hidden state**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **`decoder_input_data`** ‚Äî *What is fed into the decoder during training*\n",
    "\n",
    "* **Shape:**\n",
    "  `(#samples, max_decoder_seq_length, num_decoder_tokens)`\n",
    "* **Represents:**\n",
    "  The **Spanish target sentences**, but shifted so that each sequence **begins with `<START>`**.\n",
    "* **How it is filled:**\n",
    "  For each Spanish sentence, the model sees:\n",
    "  `<START> token1 token2 token3 ...`\n",
    "* **Purpose:**\n",
    "  This is the input that the decoder consumes at each time step to learn how to produce the next token.\n",
    "  *(This is part of teacher forcing.)*\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **`decoder_target_data`** ‚Äî *What the decoder is expected to output*\n",
    "\n",
    "* **Shape:**\n",
    "  `(#samples, max_decoder_seq_length, num_decoder_tokens)`\n",
    "* **Represents:**\n",
    "  The **expected output** for each decoder step, ending with `<END>`.\n",
    "* **How it is filled:**\n",
    "  For each Spanish sentence, this sequence is **shifted by one position**:\n",
    "  `token1 token2 token3 ... <END>`\n",
    "* **Purpose:**\n",
    "  At every training step:\n",
    "  `decoder_input_data[t] ‚Üí decoder predicts ‚Üí decoder_target_data[t]`\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Why `decoder_input_data` and `decoder_target_data` start identical\n",
    "\n",
    "They are **both zero-filled shells at initialization**, but they will be filled differently:\n",
    "\n",
    "| Matrix                | Starts With      | Used For                               |\n",
    "| --------------------- | ---------------- | -------------------------------------- |\n",
    "| `decoder_input_data`  | `<START>`        | What we feed into the decoder          |\n",
    "| `decoder_target_data` | first real token | What the decoder must learn to predict |\n",
    "\n",
    "This mismatch (shift) is what trains the decoder to generate the next word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fbfafc",
   "metadata": {},
   "source": [
    "# Training Setup (Part 2)\n",
    "\n",
    "Before training our seq2seq model, we must convert each token in each sentence into a **one-hot vector**. These vectors are grouped into a 3-dimensional NumPy matrix that stores:\n",
    "\n",
    "* the **sentence index**\n",
    "* the **timestep** within the sentence\n",
    "* the **token index** inside the vocabulary\n",
    "\n",
    "## One-Hot Example\n",
    "\n",
    "For the sentence:\n",
    "\n",
    "```\n",
    "[\"the\", \"dog\", \"licked\", \"me\"]\n",
    "```\n",
    "\n",
    "with vocabulary `[\"the\", \"dog\", \"licked\", \"me\"]`, its one-hot encoding becomes:\n",
    "\n",
    "```\n",
    "[\n",
    "  [1, 0, 0, 0],  # timestep 0 ‚Üí \"the\"\n",
    "  [0, 1, 0, 0],  # timestep 1 ‚Üí \"dog\"\n",
    "  [0, 0, 1, 0],  # timestep 2 ‚Üí \"licked\"\n",
    "  [0, 0, 0, 1],  # timestep 3 ‚Üí \"me\"\n",
    "]\n",
    "```\n",
    "\n",
    "Each **row** corresponds to a timestep, and each **column** corresponds to a position in the vocabulary.\n",
    "\n",
    "---\n",
    "\n",
    "## Building the 3-D Training Matrices\n",
    "\n",
    "We fill these matrices by setting:\n",
    "\n",
    "```\n",
    "matrix_name[line, timestep, features_dict[token]] = 1\n",
    "```\n",
    "\n",
    "This gives us three NumPy arrays:\n",
    "\n",
    "### 1. **Encoder Input Data**\n",
    "\n",
    "A sequence of one-hot vectors representing the **English input** sentence at each timestep.\n",
    "\n",
    "### 2. **Decoder Input Data**\n",
    "\n",
    "A sequence of one-hot vectors representing the **Spanish target sentence**, but shifted to begin with `<START>`.\n",
    "\n",
    "### 3. **Decoder Target Data**\n",
    "\n",
    "A sequence of one-hot vectors representing the **expected next token** in the Spanish sentence (ending with `<END>`).\n",
    "\n",
    "---\n",
    "\n",
    "## Why Two Decoder Matrices?\n",
    "\n",
    "This comes from **teacher forcing**, a technique used in seq2seq training.\n",
    "\n",
    "At timestep *t*:\n",
    "\n",
    "* the decoder receives a Spanish token from **decoder_input_data[t]**\n",
    "  (usually the correct previous token),\n",
    "* and must predict the next Spanish token in **decoder_target_data[t]**.\n",
    "\n",
    "Using the ground-truth previous token at each step makes training more stable and helps the model learn correct token transitions more quickly.\n",
    "\n",
    "Teacher forcing, therefore, requires **two** decoder matrices:\n",
    "\n",
    "* **decoder_input_data**: what we feed *into* the decoder\n",
    "* **decoder_target_data**: what the decoder must learn to output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51f80a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input timestep & token: 0 We'll\n",
      "3\n",
      "Encoder input timestep & token: 1 see\n",
      "14\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Despu√©s\n",
      "7\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 veremos\n",
      "23\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4\n",
      "Encoder input timestep & token: 0 We'll\n",
      "3\n",
      "Encoder input timestep & token: 1 see\n",
      "14\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Ya\n",
      "12\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 veremos\n",
      "23\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4\n",
      "Encoder input timestep & token: 0 We'll\n",
      "3\n",
      "Encoder input timestep & token: 1 try\n",
      "15\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Lo\n",
      "9\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 intentaremos\n",
      "20\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4\n",
      "Encoder input timestep & token: 0 We've\n",
      "4\n",
      "Encoder input timestep & token: 1 won\n",
      "17\n",
      "Encoder input timestep & token: 2 !\n",
      "0\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬°\n",
      "24\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 Hemos\n",
      "8\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 ganado\n",
      "16\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 !\n",
      "0\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5\n",
      "Encoder input timestep & token: 0 Well\n",
      "5\n",
      "Encoder input timestep & token: 1 done\n",
      "9\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Bien\n",
      "6\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 hecho\n",
      "18\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4\n",
      "Encoder input timestep & token: 0 What's\n",
      "6\n",
      "Encoder input timestep & token: 1 up\n",
      "16\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬ø\n",
      "25\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 Qu√©\n",
      "11\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 hay\n",
      "17\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 cares\n",
      "8\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬ø\n",
      "25\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 A\n",
      "5\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 qui√©n\n",
      "22\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 le\n",
      "21\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 importa\n",
      "19\n",
      "Decoder target timestep: 5\n",
      "Decoder input timestep & token: 6 ?\n",
      "4\n",
      "Decoder target timestep: 6\n",
      "Decoder input timestep & token: 7 <END>\n",
      "2\n",
      "Decoder target timestep: 7\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 drove\n",
      "10\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬ø\n",
      "25\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 Qui√©n\n",
      "10\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 condujo\n",
      "14\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 drove\n",
      "10\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬ø\n",
      "25\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 Qui√©n\n",
      "10\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 conduc√≠a\n",
      "13\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 is\n",
      "12\n",
      "Encoder input timestep & token: 2 he\n",
      "11\n",
      "Encoder input timestep & token: 3 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬ø\n",
      "25\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 Qui√©n\n",
      "10\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 es\n",
      "15\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 √©l\n",
      "26\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 ?\n",
      "4\n",
      "Decoder target timestep: 5\n",
      "Decoder input timestep & token: 6 <END>\n",
      "2\n",
      "Decoder target timestep: 6\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 is\n",
      "12\n",
      "Encoder input timestep & token: 2 it\n",
      "13\n",
      "Encoder input timestep & token: 3 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¬ø\n",
      "25\n",
      "Decoder target timestep: 1\n",
      "Decoder input timestep & token: 2 Qui√©n\n",
      "10\n",
      "Decoder target timestep: 2\n",
      "Decoder input timestep & token: 3 es\n",
      "15\n",
      "Decoder target timestep: 3\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Loop over each English‚ÄìSpanish sentence pair\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "\n",
    "    # ============================================================\n",
    "    # ENCODER: BUILD ONE-HOT VECTORS FOR ENGLISH INPUT SENTENCES\n",
    "    # ============================================================\n",
    "    # We tokenize the English sentence using the same regex used\n",
    "    # for computing max_encoder_seq_length.\n",
    "    # Each token is placed at encoder_input_data[line][timestep][token_index] = 1.\n",
    "    # ------------------------------------------------------------\n",
    "    for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        \n",
    "        # Debug print\n",
    "        print(\"Encoder input timestep & token:\", timestep, token)\n",
    "        print(input_features_dict[token])\n",
    "        \n",
    "        # Step 1A: Assign a 1 at the correct (line, timestep, token) position.\n",
    "        # This creates a one-hot vector for the English token at this timestep.\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "\n",
    "\n",
    "    # ============================================================\n",
    "    # DECODER: BUILD ONE-HOT VECTORS FOR SPANISH INPUT SENTENCES\n",
    "    # ============================================================\n",
    "    # Here we use target_doc.split() which is the same method used\n",
    "    # when computing max_decoder_seq_length.\n",
    "    #\n",
    "    # decoder_input_data receives the Spanish sequence starting with <START>.\n",
    "    # Each timestep contains a one-hot vector for the token.\n",
    "    # ------------------------------------------------------------\n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        \n",
    "        # Debug print\n",
    "        print(\"Decoder input timestep & token:\", timestep, token)\n",
    "        print(target_features_dict[token])\n",
    "\n",
    "        # Step 2: Assign 1 for decoder_input_data at this timestep.\n",
    "        # This feeds <START> token first, then the Spanish tokens.\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "\n",
    "\n",
    "        # ============================================================\n",
    "        # DECODER TARGET: SHIFTED ONE-HOT VECTORS FOR SPANISH OUTPUT\n",
    "        # ============================================================\n",
    "        # Teacher forcing:\n",
    "        #   decoder_input_data[t]  ‚Üí decoder predicts ‚Üí decoder_target_data[t]\n",
    "        #\n",
    "        # That means decoder_target_data must be ahead by one timestep.\n",
    "        #\n",
    "        # decoder_target_data[line][timestep - 1] corresponds to the\n",
    "        # expected NEXT token.\n",
    "        # ------------------------------------------------------------\n",
    "        if timestep > 0:\n",
    "\n",
    "            # Debug print\n",
    "            print(\"Decoder target timestep:\", timestep)\n",
    "\n",
    "            # Step 3: Assign the correct one-hot target at timestep - 1.\n",
    "            decoder_target_data[line, timestep - 1, target_features_dict[token]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97dd97e",
   "metadata": {},
   "source": [
    "## 1. Does `decoder_target_data` get ones at timestep 0?\n",
    "\n",
    "Look at this part:\n",
    "\n",
    "```python\n",
    "for timestep, token in enumerate(target_doc.split()):\n",
    "    decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "\n",
    "    if timestep > 0:\n",
    "        decoder_target_data[line, timestep-1, target_features_dict[token]] = 1.\n",
    "```\n",
    "\n",
    "* At `timestep = 0` (token = `<START>`):\n",
    "\n",
    "  * `decoder_input_data[line, 0, idx(\"<START>\")] = 1.` ‚úÖ\n",
    "  * `if timestep > 0:` ‚Üí **False**, so **no write** to `decoder_target_data`.\n",
    "\n",
    "So **nothing is written** to `decoder_target_data` at timestep 0.\n",
    "The *first* time we write to `decoder_target_data` is when `timestep = 1`.\n",
    "\n",
    "Concretely, for:\n",
    "\n",
    "```text\n",
    "<START> Despu√©s veremos . <END>\n",
    "```\n",
    "\n",
    "We get:\n",
    "\n",
    "| timestep | token     | write to `decoder_input_data`                     | write to `decoder_target_data`                     |\n",
    "| -------- | --------- | ------------------------------------------------- | -------------------------------------------------- |\n",
    "| 0        | `<START>` | `decoder_input_data[line, 0, idx(\"<START>\")] = 1` | *(no write: timestep > 0 is False)*                |\n",
    "| 1        | `Despu√©s` | `decoder_input_data[line, 1, idx(\"Despu√©s\")] = 1` | `decoder_target_data[line, 0, idx(\"Despu√©s\")] = 1` |\n",
    "| 2        | `veremos` | `decoder_input_data[line, 2, idx(\"veremos\")] = 1` | `decoder_target_data[line, 1, idx(\"veremos\")] = 1` |\n",
    "| 3        | `.`       | `decoder_input_data[line, 3, idx(\".\")] = 1`       | `decoder_target_data[line, 2, idx(\".\")] = 1`       |\n",
    "| 4        | `<END>`   | `decoder_input_data[line, 4, idx(\"<END>\")] = 1`   | `decoder_target_data[line, 3, idx(\"<END>\")] = 1`   |\n",
    "\n",
    "So:\n",
    "\n",
    "* `decoder_input_data` has ones from timestep `0` to `4`.\n",
    "* `decoder_target_data` has ones from timestep `0` to `3`.\n",
    "\n",
    "Timestep `4` in `decoder_target_data` stays all zeros.\n",
    "\n",
    "## 2. So yes: the last row of `decoder_target_data` is all zeros\n",
    "\n",
    "Exactly:\n",
    "\n",
    "* Sequence length (for this sentence) = 5 timesteps.\n",
    "* We only ever write to `decoder_target_data` up to `timestep - 1`, where `timestep` goes from `1` to `4`.\n",
    "* That means **the last timestep in `decoder_target_data` (index 4) is never written to** and remains all zeros.\n",
    "\n",
    "This is expected and normal for this simple implementation.\n",
    "\n",
    "Intuition:\n",
    "\n",
    "* At training time, we teach the model:\n",
    "\n",
    "  * Given `<START>` ‚Üí predict `Despu√©s`\n",
    "  * Given `Despu√©s` ‚Üí predict `veremos`\n",
    "  * Given `veremos` ‚Üí predict `.`\n",
    "  * Given `.` ‚Üí predict `<END>`\n",
    "* After `<END>`, we don‚Äôt care about ‚Äúnext token‚Äù, so that ‚Äúnext step‚Äù in `decoder_target_data` is just zeros (no target).\n",
    "\n",
    "In a more advanced setup you might:\n",
    "\n",
    "* apply a **mask** to ignore that last timestep in the loss, or\n",
    "* pad sequences and mask padded positions.\n",
    "\n",
    "In this Codecademy-style tutorial, they keep it simple and just leave that last row as zeros, which is ok ‚Äî the model still trains fine.\n",
    "\n",
    "## 3. Summary in one sentence\n",
    "\n",
    "* `decoder_input_data` has tokens from `<START>` to `<END>`.\n",
    "* `decoder_target_data` is the **same sentence shifted one step left**, so it **does not include the `<START>` position**, and the last timestep is unused (all zeros).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55d392",
   "metadata": {},
   "source": [
    "# Encoder Training Setup\n",
    "\n",
    "To build the encoder portion of our seq2seq model, we assemble it using **Keras layers**. The encoder‚Äôs job is to read an input sentence (represented as a sequence of one-hot vectors) and compress it into two internal states that summarize the entire meaning of the sentence. These two states will then be used to initialize the decoder so it can begin generating the translated output.\n",
    "\n",
    "This process involves defining an input layer, connecting it to an LSTM layer, and extracting the LSTM‚Äôs internal states.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Importing the Required Layers**\n",
    "\n",
    "We begin by importing the Keras components that allow us to construct the encoder:\n",
    "\n",
    "```python\n",
    "from keras.layers import Input, LSTM\n",
    "from keras.models import Model\n",
    "```\n",
    "\n",
    "* `Input` lets us define the shape of the data we will feed into the model.\n",
    "* `LSTM` provides the recurrent layer that processes sequences step-by-step.\n",
    "* `Model` will later allow us to package the encoder into a full Keras model.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Defining the Encoder Input Layer**\n",
    "\n",
    "The encoder expects a 3-dimensional tensor:\n",
    "\n",
    "1. **batch size** (number of sentences processed at once ‚Äî left as `None`)\n",
    "2. **timesteps** (number of tokens in a sentence ‚Äî also variable ‚Üí `None`)\n",
    "3. **features** (the one-hot vector size = number of encoder tokens)\n",
    "\n",
    "We specify this with:\n",
    "\n",
    "```python\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "```\n",
    "\n",
    "This tells Keras:\n",
    "‚ÄúEach sentence is a sequence of unknown length, and each timestep is a vector with `num_encoder_tokens` features.‚Äù\n",
    "\n",
    "The model can now handle sentences of different lengths during training.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Adding the Encoder LSTM Layer**\n",
    "\n",
    "We now create the LSTM that will process each one-hot vector one timestep at a time. We choose a hidden dimensionality of 100 ‚Äî meaning the encoder will compress the entire sentence into a **100-dimensional representation**.\n",
    "\n",
    "```python\n",
    "encoder_lstm = LSTM(100, return_state=True)\n",
    "```\n",
    "\n",
    "* `100` ‚Üí size of the internal memory\n",
    "* `return_state=True` ‚Üí instructs the LSTM to give us not only its output, but also its final hidden state (`h`) and cell state (`c`)\n",
    "\n",
    "These states carry forward the meaning of everything the encoder has read.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Connecting Inputs to the LSTM**\n",
    "\n",
    "We now pass the one-hot input sequence through the LSTM:\n",
    "\n",
    "```python\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "```\n",
    "\n",
    "This call returns:\n",
    "\n",
    "* `encoder_outputs` ‚Üí the LSTM output at every timestep (not needed here)\n",
    "* `state_hidden` ‚Üí final hidden state (**h**), summarizing short-term context\n",
    "* `state_cell` ‚Üí final cell state (**c**), summarizing long-term context\n",
    "\n",
    "Together, these two vectors form the **sentence embedding** that the decoder will use to begin generating the translation.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Saving the Encoder States**\n",
    "\n",
    "We keep only the two internal states and discard the per-timestep outputs:\n",
    "\n",
    "```python\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "```\n",
    "\n",
    "These states are the *only* output of the encoder that matters. They act like a compressed memory of the entire input sentence, capturing the key structure and meaning that will guide the decoder as it produces the translated sentence.\n",
    "\n",
    "---\n",
    "\n",
    "The encoder is now fully constructed. It accepts a sequence of English tokens, processes it through an LSTM, and outputs a pair of internal states representing the entire sequence ‚Äî exactly what the decoder needs to begin generating a translation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58aeb7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 20:30:50.048517: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "# Step 1: Define the encoder input layer\n",
    "# - Batch size: None (flexible)\n",
    "# - Timesteps: None (variable sequence length)\n",
    "# - Features: num_encoder_tokens (one-hot vector size)\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "# Step 2: Build the encoder LSTM layer\n",
    "# - Dimensionality: 256 units\n",
    "# - return_state=True so we can extract the hidden + cell states\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "\n",
    "# Step 3: Pass the inputs through the LSTM\n",
    "# This returns:\n",
    "#   encoder_outputs ‚Üí full sequence outputs (unused here)\n",
    "#   state_hidden     ‚Üí final hidden state (h)\n",
    "#   state_cell       ‚Üí final cell state (c)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# Step 4: Store the two states in a list for the decoder\n",
    "encoder_states = [state_hidden, state_cell]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10320232",
   "metadata": {},
   "source": [
    "# Decoder Training Setup\n",
    "\n",
    "The decoder is the second half of the seq2seq architecture. While the encoder **reads** the input sentence and compresses it into internal states, the decoder **uses those states** to generate the output sentence step by step. Structurally, the decoder looks very similar to the encoder: it has its own input layer, its own LSTM, and a final Dense layer with a Softmax activation to produce token probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Decoder Inputs: Feeding the Target Language to the Model\n",
    "\n",
    "Just as the encoder receives one-hot vectors for the **source language**, the decoder receives one-hot vectors for the **target language** (e.g., Spanish). We allow variable-length sentences using `None` for the timestep dimension:\n",
    "\n",
    "```python\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "* `None` ‚Üí variable number of timesteps (sentence length)\n",
    "* `num_decoder_tokens` ‚Üí size of the target vocabulary (the depth of each one-hot vector)\n",
    "\n",
    "At each timestep, `decoder_inputs` will contain one target token (often starting with `<START>`) in one-hot form.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Decoder LSTM: Returning Full Sequences and States\n",
    "\n",
    "The decoder‚Äôs LSTM must output a **prediction at every timestep**, so we set `return_sequences=True`. We also keep `return_state=True`, because the final hidden and cell states will be useful later (especially during inference):\n",
    "\n",
    "```python\n",
    "decoder_lstm = LSTM(100, return_sequences=True, return_state=True)\n",
    "# This time we care about full return sequences\n",
    "```\n",
    "\n",
    "* `100` ‚Üí dimensionality of the LSTM‚Äôs hidden state (you previously used 256; 100 is just the example in the text).\n",
    "* `return_sequences=True` ‚Üí we get an output vector for **each timestep**, not just the last one.\n",
    "* `return_state=True` ‚Üí we still obtain the final hidden and cell states (`decoder_state_hidden`, `decoder_state_cell`).\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Linking Encoder and Decoder via Initial State\n",
    "\n",
    "The critical difference from the encoder is how the decoder is **initialized**.\n",
    "Instead of starting from zero states, the decoder LSTM is initialized with the **final states of the encoder**, which carry the compressed meaning of the input sentence:\n",
    "\n",
    "```python\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(\n",
    "    decoder_inputs,\n",
    "    initial_state=encoder_states\n",
    ")\n",
    "```\n",
    "\n",
    "Where:\n",
    "\n",
    "* `decoder_inputs` ‚Üí one-hot Spanish tokens (shifted sequence with `<START>`).\n",
    "* `encoder_states` ‚Üí `[state_hidden, state_cell]` from the encoder LSTM.\n",
    "* `decoder_outputs` ‚Üí output at each timestep (sequence of hidden vectors).\n",
    "* `decoder_state_hidden`, `decoder_state_cell` ‚Üí final states of the decoder (useful for step-by-step decoding during inference).\n",
    "\n",
    "During **training**, we primarily care about `decoder_outputs`, because each timestep of this sequence will be mapped to a probability distribution over all possible target tokens.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Dense + Softmax: From Hidden States to Token Probabilities\n",
    "\n",
    "The LSTM‚Äôs hidden state at each timestep has size equal to the LSTM dimensionality (e.g., 100), but we need a vector of size `num_decoder_tokens` that represents **probabilities over all target tokens**. That‚Äôs the job of the final Dense layer:\n",
    "\n",
    "```python\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "```\n",
    "\n",
    "* `Dense(num_decoder_tokens, ...)` maps each LSTM output from shape `[batch_size, timesteps, 100]` to `[batch_size, timesteps, num_decoder_tokens]`.\n",
    "* `activation='softmax'` ensures that for each timestep:\n",
    "\n",
    "  * all values are between 0 and 1\n",
    "  * the probabilities across all tokens sum to 1\n",
    "\n",
    "So at every timestep, the decoder now outputs a **probability distribution over the entire target vocabulary** (e.g., ‚Äú0.7 for ‚ÄòHola‚Äô, 0.2 for ‚ÄòAdi√≥s‚Äô, 0.1 split among others‚Äù).\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Why a Dense Layer (and Why Softmax)?\n",
    "\n",
    "Keras could use different kinds of output layers, but `Dense` is the simplest and most common for classification-like tasks at each timestep. Here the ‚Äúclasses‚Äù are the **target tokens**:\n",
    "\n",
    "* The LSTM handles **temporal dependencies** (what came before).\n",
    "* The Dense + Softmax layer turns each hidden vector into a **token prediction**.\n",
    "\n",
    "Together with teacher forcing and the encoder states, this setup allows the decoder to:\n",
    "\n",
    "1. Start from the encoder‚Äôs understanding of the input sentence.\n",
    "2. Read the previous target token (from `decoder_inputs`).\n",
    "3. Output a probability distribution over the next token (via `decoder_outputs` after the Dense+Softmax layer).\n",
    "\n",
    "This is how the model learns to generate full translations, one token at a time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b347decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Step 1: Import Input, LSTM, and Dense\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ENCODER SETUP\n",
    "# ---------------------------------------------------------\n",
    "# Step 2: Create encoder input layer\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "\n",
    "# Step 3: Encoder LSTM (returns final hidden & cell states)\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "\n",
    "# Step 4: Extract encoder outputs and states\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# Step 5: Package encoder states to pass into decoder\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# DECODER SETUP\n",
    "# ---------------------------------------------------------\n",
    "# Step 6: Decoder input layer (target-language one-hot vectors)\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# Step 7: Decoder LSTM (returns full sequences + final states)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "\n",
    "# Step 8: Run decoder LSTM using encoder states as initial state\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(\n",
    "    decoder_inputs,\n",
    "    initial_state=encoder_states\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FINAL DENSE + SOFTMAX LAYER\n",
    "# ---------------------------------------------------------\n",
    "# Step 9: Build a Dense layer that outputs probabilities over all decoder tokens\n",
    "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "\n",
    "# Step 10: Apply the Dense layer to decoder outputs\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49436429",
   "metadata": {},
   "source": [
    "# Build and Train the Seq2Seq Model\n",
    "\n",
    "Once the encoder and decoder are wired together, we wrap them into a single **sequence-to-sequence (seq2seq)** model, compile it, and train it on our one-hot encoded data.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Defining the Seq2Seq Model\n",
    "\n",
    "Our model has:\n",
    "\n",
    "* **Two inputs:**\n",
    "\n",
    "  * `encoder_inputs` ‚Üí one-hot encoded source sentences (e.g., English)\n",
    "  * `decoder_inputs` ‚Üí one-hot encoded shifted target sentences (e.g., Spanish with `<START>`)\n",
    "* **One output:**\n",
    "\n",
    "  * `decoder_outputs` ‚Üí probability distributions over the target vocabulary at each timestep\n",
    "\n",
    "We connect everything via Keras‚Äô `Model` API:\n",
    "\n",
    "```python\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "```\n",
    "\n",
    "This tells Keras:\n",
    "\n",
    "> ‚ÄúGiven both the encoder input sequence and the decoder input sequence, learn to produce the decoder output sequence.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Compiling the Model\n",
    "\n",
    "Before training, we must **compile** the model by specifying:\n",
    "\n",
    "* an **optimizer** ‚Üí how weights are updated\n",
    "* a **loss function** ‚Üí how wrong each prediction is\n",
    "* optional **metrics** ‚Üí extra statistics to monitor (e.g. accuracy)\n",
    "\n",
    "In this setup:\n",
    "\n",
    "* **Optimizer:** `\"rmsprop\"`\n",
    "  A variant of gradient descent that adapts the learning rate per parameter and often works well for recurrent models.\n",
    "\n",
    "* **Loss:** `\"categorical_crossentropy\"`\n",
    "  The standard loss for multi-class classification when targets are one-hot vectors. At each timestep, the model is choosing among all possible target tokens.\n",
    "\n",
    "* **Metric:** `\"accuracy\"`\n",
    "  Tracks how often the predicted token with highest probability matches the true token.\n",
    "\n",
    "```python\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Fitting (Training) the Model\n",
    "\n",
    "To train the model, we call `.fit()` with:\n",
    "\n",
    "* **Inputs:**\n",
    "\n",
    "  * `[encoder_input_data, decoder_input_data]`\n",
    "\n",
    "    * `encoder_input_data` ‚Üí English sentences as 3D tensors of one-hot vectors\n",
    "      shape: `(num_samples, max_encoder_seq_length, num_encoder_tokens)`\n",
    "    * `decoder_input_data` ‚Üí Spanish sentences shifted with `<START>` at the beginning\n",
    "      shape: `(num_samples, max_decoder_seq_length, num_decoder_tokens)`\n",
    "\n",
    "* **Targets:**\n",
    "\n",
    "  * `decoder_target_data` ‚Üí Spanish sentences shifted one step ahead\n",
    "    (what the decoder should output at each timestep)\n",
    "\n",
    "* **Hyperparameters:**\n",
    "\n",
    "  * `batch_size=10` ‚Üí number of sentence pairs processed before each weight update\n",
    "  * `epochs=100` ‚Üí how many passes over the entire dataset\n",
    "  * `validation_split=0.2` ‚Üí 20% of the data is kept aside for validation\n",
    "\n",
    "```python\n",
    "model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=10,\n",
    "    epochs=100,\n",
    "    validation_split=0.2\n",
    ")\n",
    "```\n",
    "\n",
    "Conceptually, at each training step the model sees:\n",
    "\n",
    "* an **English input sequence** (to encode),\n",
    "* a **Spanish input sequence** with `<START>` tokens (to drive the decoder),\n",
    "* and it learns to produce the **next Spanish tokens** in `decoder_target_data` using **teacher forcing**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. What We Get After Training\n",
    "\n",
    "After training:\n",
    "\n",
    "* The encoder has learned how to compress an input sentence into hidden states.\n",
    "* The decoder has learned how to use those states, plus previous target tokens, to predict the next token at each timestep.\n",
    "* Together, they form a seq2seq model that can be adapted for translation or other sequence generation tasks (with additional inference-time wiring).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cd3f6d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KerasTensor shape=(None, None, 18), dtype=float32, sparse=False, name=keras_tensor_4>\n",
      "<KerasTensor shape=(None, None, 27), dtype=float32, sparse=False, name=keras_tensor_8>\n",
      "<KerasTensor shape=(None, None, 27), dtype=float32, sparse=False, name=keras_tensor_12>\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inputs)\n",
    "print(decoder_inputs)\n",
    "print(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58dc6769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ<span style=\"font-weight: bold\"> Layer (type)        </span>‚îÉ<span style=\"font-weight: bold\"> Output Shape      </span>‚îÉ<span style=\"font-weight: bold\">    Param # </span>‚îÉ<span style=\"font-weight: bold\"> Connected to      </span>‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ input_layer_2       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)  ‚îÇ          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       ‚îÇ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">281,600</span> ‚îÇ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îÇ                     ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       ‚îÇ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     ‚îÇ    <span style=\"color: #00af00; text-decoration-color: #00af00\">290,816</span> ‚îÇ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      ‚îÇ            ‚îÇ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     ‚îÇ\n",
       "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      ‚îÇ            ‚îÇ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      ‚îÇ\n",
       "‚îÇ                     ‚îÇ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       ‚îÇ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)  ‚îÇ      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,939</span> ‚îÇ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
       "‚îÉ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
       "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
       "‚îÇ input_layer_1       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ input_layer_2       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)  ‚îÇ          \u001b[38;5;34m0\u001b[0m ‚îÇ -                 ‚îÇ\n",
       "‚îÇ (\u001b[38;5;33mInputLayer\u001b[0m)        ‚îÇ                   ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     ‚îÇ    \u001b[38;5;34m281,600\u001b[0m ‚îÇ input_layer_1[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îÇ                     ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       ‚îÇ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     ‚îÇ    \u001b[38;5;34m290,816\u001b[0m ‚îÇ input_layer_2[\u001b[38;5;34m0\u001b[0m]‚Ä¶ ‚îÇ\n",
       "‚îÇ                     ‚îÇ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      ‚îÇ            ‚îÇ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     ‚îÇ\n",
       "‚îÇ                     ‚îÇ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      ‚îÇ            ‚îÇ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      ‚îÇ\n",
       "‚îÇ                     ‚îÇ \u001b[38;5;34m256\u001b[0m)]             ‚îÇ            ‚îÇ                   ‚îÇ\n",
       "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
       "‚îÇ dense (\u001b[38;5;33mDense\u001b[0m)       ‚îÇ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)  ‚îÇ      \u001b[38;5;34m6,939\u001b[0m ‚îÇ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,355</span> (2.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m579,355\u001b[0m (2.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,355</span> (2.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m579,355\u001b[0m (2.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Training the model:\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0625 - loss: 1.3057 - val_accuracy: 0.0000e+00 - val_loss: 1.4596\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.0625 - loss: 1.2986 - val_accuracy: 0.1389 - val_loss: 1.4554\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.1146 - loss: 1.2926 - val_accuracy: 0.1389 - val_loss: 1.4514\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.1146 - loss: 1.2869 - val_accuracy: 0.1389 - val_loss: 1.4473\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.1042 - loss: 1.2810 - val_accuracy: 0.1111 - val_loss: 1.4427\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.0833 - loss: 1.2747 - val_accuracy: 0.0833 - val_loss: 1.4372\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.0833 - loss: 1.2672 - val_accuracy: 0.0833 - val_loss: 1.4298\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.0833 - loss: 1.2577 - val_accuracy: 0.0833 - val_loss: 1.4187\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.0833 - loss: 1.2445 - val_accuracy: 0.0833 - val_loss: 1.4010\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.0833 - loss: 1.2247 - val_accuracy: 0.0833 - val_loss: 1.3775\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.0833 - loss: 1.1996 - val_accuracy: 0.0833 - val_loss: 1.3618\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.0833 - loss: 1.1814 - val_accuracy: 0.0833 - val_loss: 1.3461\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.0833 - loss: 1.1626 - val_accuracy: 0.0833 - val_loss: 1.3278\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.0833 - loss: 1.1398 - val_accuracy: 0.0833 - val_loss: 1.3206\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.0833 - loss: 1.1243 - val_accuracy: 0.0833 - val_loss: 1.3152\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.0833 - loss: 1.1102 - val_accuracy: 0.0833 - val_loss: 1.3192\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.0833 - loss: 1.1051 - val_accuracy: 0.0833 - val_loss: 1.3178\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0833 - loss: 1.0962 - val_accuracy: 0.0833 - val_loss: 1.3224\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.0833 - loss: 1.0936 - val_accuracy: 0.0833 - val_loss: 1.3222\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.0833 - loss: 1.0872 - val_accuracy: 0.0833 - val_loss: 1.3242\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.0833 - loss: 1.0836 - val_accuracy: 0.0833 - val_loss: 1.3238\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.0833 - loss: 1.0787 - val_accuracy: 0.0833 - val_loss: 1.3237\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.0833 - loss: 1.0745 - val_accuracy: 0.0833 - val_loss: 1.3231\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.0833 - loss: 1.0700 - val_accuracy: 0.0833 - val_loss: 1.3223\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0833 - loss: 1.0655 - val_accuracy: 0.0833 - val_loss: 1.3213\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.0833 - loss: 1.0610 - val_accuracy: 0.0833 - val_loss: 1.3202\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.0833 - loss: 1.0565 - val_accuracy: 0.0833 - val_loss: 1.3189\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.0833 - loss: 1.0520 - val_accuracy: 0.0833 - val_loss: 1.3175\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0833 - loss: 1.0475 - val_accuracy: 0.0833 - val_loss: 1.3159\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.0833 - loss: 1.0431 - val_accuracy: 0.0833 - val_loss: 1.3141\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.0833 - loss: 1.0387 - val_accuracy: 0.0833 - val_loss: 1.3122\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1146 - loss: 1.0343 - val_accuracy: 0.0833 - val_loss: 1.3102\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1354 - loss: 1.0299 - val_accuracy: 0.1111 - val_loss: 1.3082\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1354 - loss: 1.0255 - val_accuracy: 0.1667 - val_loss: 1.3062\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1458 - loss: 1.0211 - val_accuracy: 0.1667 - val_loss: 1.3042\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.1458 - loss: 1.0168 - val_accuracy: 0.1667 - val_loss: 1.3023\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1562 - loss: 1.0124 - val_accuracy: 0.1667 - val_loss: 1.3005\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1562 - loss: 1.0081 - val_accuracy: 0.1667 - val_loss: 1.2987\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.1562 - loss: 1.0037 - val_accuracy: 0.1667 - val_loss: 1.2971\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1562 - loss: 0.9998 - val_accuracy: 0.1667 - val_loss: 1.2950\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1562 - loss: 0.9943 - val_accuracy: 0.1667 - val_loss: 1.2949\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.1562 - loss: 0.9944 - val_accuracy: 0.1667 - val_loss: 1.2906\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1562 - loss: 0.9844 - val_accuracy: 0.1667 - val_loss: 1.2935\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.1562 - loss: 0.9862 - val_accuracy: 0.1667 - val_loss: 1.2892\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.1562 - loss: 0.9749 - val_accuracy: 0.1667 - val_loss: 1.2861\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.1562 - loss: 0.9739 - val_accuracy: 0.1667 - val_loss: 1.2830\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.1562 - loss: 0.9629 - val_accuracy: 0.1667 - val_loss: 1.2836\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.1562 - loss: 0.9646 - val_accuracy: 0.1667 - val_loss: 1.2784\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.1562 - loss: 0.9515 - val_accuracy: 0.1667 - val_loss: 1.2776\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.1562 - loss: 0.9554 - val_accuracy: 0.1667 - val_loss: 1.2740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f8689fe1510>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# BUILD TRAINING MODEL\n",
    "# ---------------------------------------------------------\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "print(\"Model summary:\\n\")\n",
    "training_model.summary()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# COMPILE THE MODEL\n",
    "# ---------------------------------------------------------\n",
    "training_model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TRAINING CONFIGURATION\n",
    "# ---------------------------------------------------------\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "\n",
    "print(\"Training the model:\\n\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FIT THE MODEL\n",
    "# ---------------------------------------------------------\n",
    "training_model.fit(\n",
    "    [encoder_input_data, decoder_input_data],\n",
    "    decoder_target_data,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a111eb",
   "metadata": {},
   "source": [
    "# Setup for Testing (Seq2Seq Inference)\n",
    "\n",
    "After training, we want to **generate translations** for new English sentences. During training we used **teacher forcing** (we knew the whole Spanish sentence and fed it in at once), but at test time we **don‚Äôt know the target sequence**. We must decode **step by step**, predicting one token at a time and feeding predictions back into the model.\n",
    "\n",
    "To do that, we split the trained seq2seq network into two separate models:\n",
    "\n",
    "* an **encoder model** (turns an input sentence into final states)\n",
    "* a **decoder model** (uses those states to generate the target sentence one token at a time)\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Encoder Model for Inference\n",
    "\n",
    "The encoder‚Äôs job at inference time is simple:\n",
    "\n",
    "* Take a new English sentence as input.\n",
    "* Return the final hidden and cell states of the encoder LSTM.\n",
    "\n",
    "We reuse the trained `encoder_inputs` and `encoder_states` to define an **inference encoder model**:\n",
    "\n",
    "```python\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "```\n",
    "\n",
    "* Input: `encoder_inputs` (one-hot or embedded English sequence).\n",
    "* Output: `encoder_states = [state_hidden, state_cell]` from the trained encoder LSTM.\n",
    "\n",
    "These states summarize the entire input sentence and will be used to initialize the decoder.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Placeholder Inputs for Decoder States\n",
    "\n",
    "At test time, decoding is iterative:\n",
    "\n",
    "1. Start with the encoder‚Äôs final states.\n",
    "2. Predict the next token.\n",
    "3. Use the **updated** decoder states to predict the next token again.\n",
    "4. Repeat until `<END>` is produced or a max length is reached.\n",
    "\n",
    "To support this loop, we create **input layers** that act as placeholders for the decoder‚Äôs hidden and cell states:\n",
    "\n",
    "```python\n",
    "latent_dim = 256  # must match the LSTM dimensionality\n",
    "\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "```\n",
    "\n",
    "* `decoder_state_input_hidden` ‚Üí placeholder for previous hidden state `h_{t-1}`\n",
    "* `decoder_state_input_cell` ‚Üí placeholder for previous cell state `c_{t-1}`\n",
    "* `decoder_states_inputs` ‚Üí list grouping both together\n",
    "\n",
    "On the **first decoding step**, these will be filled with the encoder‚Äôs final states. On subsequent steps, they‚Äôll be filled with the decoder‚Äôs own updated states from the previous timestep.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Running the Decoder LSTM One Step at a Time\n",
    "\n",
    "We now reuse the **trained** decoder components:\n",
    "\n",
    "* `decoder_lstm` ‚Üí the LSTM layer we trained for the decoder\n",
    "* `decoder_dense` ‚Üí the Dense + softmax layer that maps hidden states to token probabilities\n",
    "\n",
    "At inference, the decoder LSTM is called with:\n",
    "\n",
    "* `decoder_inputs` ‚Üí the current token‚Äôs one-hot vector (e.g. `<START>` or previous prediction)\n",
    "* `decoder_states_inputs` ‚Üí the previous timestep‚Äôs hidden and cell states\n",
    "\n",
    "```python\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(\n",
    "    decoder_inputs,\n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "# New states after processing one timestep:\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# Map LSTM outputs to probability distribution over target tokens:\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "```\n",
    "\n",
    "* `decoder_outputs` ‚Üí probabilities over all Spanish tokens for the current timestep.\n",
    "* `decoder_states` ‚Üí updated hidden and cell states to be fed back in the **next** decoding step.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Building the Decoder Inference Model\n",
    "\n",
    "Finally, we wrap this logic into a **decoder model** that, given:\n",
    "\n",
    "* the current token (`decoder_inputs`)\n",
    "* the previous hidden/cell states (`decoder_states_inputs`)\n",
    "\n",
    "returns:\n",
    "\n",
    "* the token probabilities for the current step (`decoder_outputs`)\n",
    "* the updated hidden/cell states (`decoder_states`)\n",
    "\n",
    "```python\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "```\n",
    "\n",
    "So during inference, the decoding loop looks like:\n",
    "\n",
    "1. Use `encoder_model` to get encoder states from an English sentence.\n",
    "2. Initialize `decoder_model` with:\n",
    "\n",
    "   * input token = `<START>`\n",
    "   * states = encoder states\n",
    "3. Get:\n",
    "\n",
    "   * predicted next-token distribution\n",
    "   * updated states\n",
    "4. Choose next token (e.g., argmax), feed it back as `decoder_inputs` together with updated states.\n",
    "5. Repeat until `<END>` or max length.\n",
    "\n",
    "This step-by-step setup makes the trained seq2seq network capable of **generating translations autonomously**, without knowing the target sequence in advance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7520a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Step 2: Extract encoder layers and build encoder_model\n",
    "# ---------------------------------------------------------\n",
    "# training_model.input[0] = encoder input layer\n",
    "encoder_inputs = training_model.input[0]\n",
    "\n",
    "# training_model.layers[2].output contains:\n",
    "# (encoder_outputs, state_h_enc, state_c_enc)\n",
    "encoder_outputs, state_h_enc, state_c_enc = training_model.layers[2].output\n",
    "\n",
    "# Final encoder states used to initialize decoder at inference\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "\n",
    "# Encoder inference model\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 3: Build decoder state input placeholders for inference\n",
    "# ---------------------------------------------------------\n",
    "latent_dim = 256  # must match the training LSTM size\n",
    "\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "\n",
    "# Combine into list\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 4: Run trained decoder LSTM for one timestep at inference\n",
    "# ---------------------------------------------------------\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(\n",
    "    decoder_inputs,\n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "# Save new states\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 5: Pass outputs through the trained Dense layer\n",
    "# ---------------------------------------------------------\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Step 6: Build final decoder inference model\n",
    "# ---------------------------------------------------------\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d4e383",
   "metadata": {},
   "source": [
    "# The Test Function for Seq2Seq Inference\n",
    "\n",
    "Once the encoder‚Äìdecoder models are trained and we‚Äôve built separate **inference models**, we can finally test the system on a new English sentence. For that, we create a **test (decode) function** that:\n",
    "\n",
    "1. Takes a **NumPy matrix** representing the English input sentence.\n",
    "2. Uses the **encoder model** to get the sentence representation (states).\n",
    "3. Uses the **decoder model** step by step to generate the Spanish translation.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Getting the Encoder States from the Test Input\n",
    "\n",
    "At test time, the English sentence is already preprocessed and vectorized into a NumPy array with shape:\n",
    "\n",
    "* `(1, max_encoder_seq_length, num_encoder_tokens)`\n",
    "\n",
    "We pass this test input through the **encoder inference model**:\n",
    "\n",
    "```python\n",
    "# test_input is a NumPy matrix representing one English sentence\n",
    "states = encoder_model.predict(test_input)\n",
    "```\n",
    "\n",
    "* `encoder_model` returns the **final hidden state** and **cell state** of the encoder LSTM.\n",
    "* These states summarize the meaning of the entire English sentence.\n",
    "* We will use these as the **initial state** for the decoder.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Initializing the Target Sequence for the Decoder\n",
    "\n",
    "The decoder works token by token. At the very start of translation, we need an initial **target sequence** of shape:\n",
    "\n",
    "* batch size = `1` (we decode one sentence at a time)\n",
    "* timesteps = `1` (we start with just one token)\n",
    "* features = `num_decoder_tokens` (size of the Spanish vocabulary)\n",
    "\n",
    "So we create:\n",
    "\n",
    "```python\n",
    "target_sequence = np.zeros((1, 1, num_decoder_tokens))\n",
    "```\n",
    "\n",
    "This is a **3D one-hot tensor** where we will set exactly one position to 1 for the first timestep.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Seeding the Decoder with the `<START>` Token\n",
    "\n",
    "We know that every generated Spanish sentence must begin with a **start token**, e.g. `\"<START>\"`. We one-hot encode this token in our `target_sequence`:\n",
    "\n",
    "```python\n",
    "target_sequence[0, 0, target_features_dict['<START>']] = 1.\n",
    "```\n",
    "\n",
    "* `target_features_dict` maps each Spanish token (like `\"<START>\"`, `\"Estoy\"`, `\"feliz\"`, `\"<END>\"`, etc.) to an index.\n",
    "* We set the entry for `\"<START>\"` to `1.` and leave all others at `0.`\n",
    "\n",
    "This tells the decoder:\n",
    "\n",
    "> ‚ÄúAt timestep 0, the previous token is `<START>` ‚Äî now predict the next word.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Preparing the String for the Generated Translation\n",
    "\n",
    "As the decoder predicts tokens step by step, we need somewhere to accumulate them as a human-readable sentence. We start with an empty string:\n",
    "\n",
    "```python\n",
    "decoded_sentence = ''\n",
    "```\n",
    "\n",
    "Inside the decoding loop, we‚Äôll:\n",
    "\n",
    "1. Run the decoder on `target_sequence` + current states.\n",
    "2. Get a probability distribution over the next token.\n",
    "3. Pick the **most likely token** (e.g., using `argmax`).\n",
    "4. Append that token to `decoded_sentence`.\n",
    "5. Update `target_sequence` to contain this new token.\n",
    "6. Feed the updated `target_sequence` and updated states back into the decoder.\n",
    "\n",
    "We continue until we generate the `\"<END>\"` token or reach a maximum length.\n",
    "Finally, the function returns `decoded_sentence` as the Spanish translation of the input English sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81adb100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
      "-\n",
      "Input sentence: We'll see.\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step\n",
      "-\n",
      "Input sentence: We'll see.\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step\n",
      "-\n",
      "Input sentence: We'll try.\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step\n",
      "-\n",
      "Input sentence: We've won!\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
      "-\n",
      "Input sentence: Well done.\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "-\n",
      "Input sentence: What's up?\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "-\n",
      "Input sentence: Who cares?\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "-\n",
      "Input sentence: Who drove?\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "-\n",
      "Input sentence: Who drove?\n",
      "Decoded sentence: \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "-\n",
      "Input sentence: Who is he?\n",
      "Decoded sentence: \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Decode function required by the instructions\n",
    "# ---------------------------------------------------------\n",
    "def decode_sequence(test_input):\n",
    "    # Step 1: Encode input sentence ‚Üí get encoder final states\n",
    "    encoder_states_value = encoder_model.predict(test_input)\n",
    "\n",
    "    # Step 2: Initialize decoder states with encoder states\n",
    "    decoder_states_value = encoder_states_value\n",
    "\n",
    "    # Step 3: Create an empty target sequence (batch 1, timestep 1)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "\n",
    "    # Step 4: Set the <START> token to 1\n",
    "    target_seq[0, 0, target_features_dict[\"<START>\"]] = 1.\n",
    "\n",
    "    decoded_sentence = ''\n",
    "    return decoded_sentence\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Test the decode function on first 10 samples\n",
    "# ---------------------------------------------------------\n",
    "for seq_index in range(10):\n",
    "    test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(test_input)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_docs[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbbb420",
   "metadata": {},
   "source": [
    "# Test Function (Part 2): Generating Text with the Trained Seq2Seq Model\n",
    "\n",
    "Now that we have separate **encoder** and **decoder** models for inference, we can finally use them to *generate* a Spanish translation from an English sentence. This happens inside the `decode_sequence()` function and is done **one token at a time**.\n",
    "\n",
    "The key idea:\n",
    "\n",
    "* The **encoder** compresses the entire English sentence into two state vectors.\n",
    "* The **decoder** takes those states and **generates the Spanish sentence step by step**, updating its internal state after each predicted word.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. When Do We Stop Decoding?\n",
    "\n",
    "We don‚Äôt want the model to generate infinite text, so we decode in a `while` loop and stop when:\n",
    "\n",
    "1. The model generates the token `\"<END>\"`, **or**\n",
    "2. The length of the decoded Spanish sentence reaches `max_decoder_seq_length`.\n",
    "\n",
    "The skeleton looks like:\n",
    "\n",
    "```python\n",
    "decoded_sentence = \"\"\n",
    "\n",
    "while True:\n",
    "    # 1. Get predictions from decoder_model\n",
    "    # 2. Choose the most probable token\n",
    "    # 3. Append token to decoded_sentence\n",
    "    # 4. Stop if <END> or max length\n",
    "    # 5. Prepare next input token and states\n",
    "    pass\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Running One Decoder Step\n",
    "\n",
    "At each step, we call the **decoder inference model** with:\n",
    "\n",
    "* `target_seq` ‚Üí the current input token to the decoder (initially `<START>`)\n",
    "* `decoder_states_value` ‚Üí the current hidden and cell states\n",
    "\n",
    "```python\n",
    "output_tokens, new_decoder_hidden_state, new_decoder_cell_state = decoder_model.predict(\n",
    "    [target_seq] + decoder_states_value\n",
    ")\n",
    "```\n",
    "\n",
    "Here:\n",
    "\n",
    "* `output_tokens` is a 3D tensor with shape `(1, 1, num_decoder_tokens)`\n",
    "\n",
    "  * It contains the **probability distribution** over all Spanish tokens at the current timestep.\n",
    "* `new_decoder_hidden_state` and `new_decoder_cell_state` are the **updated states** after processing this token. They will be used for the *next* decoding step.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Choosing the Next Token\n",
    "\n",
    "We take the most probable token (greedy decoding) using `np.argmax()` on the last timestep of `output_tokens`:\n",
    "\n",
    "```python\n",
    "sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "\n",
    "decoded_sentence += \" \" + sampled_token\n",
    "```\n",
    "\n",
    "* `output_tokens[0, -1, :]` selects:\n",
    "\n",
    "  * batch `0`\n",
    "  * last timestep (`-1`)\n",
    "  * all token probabilities\n",
    "* `np.argmax(...)` gives us the index of the highest-probability token.\n",
    "* `reverse_target_features_dict` maps indices back to actual Spanish words/tokens.\n",
    "* We append this token to `decoded_sentence`.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Stopping Condition: `<END>` or Max Length\n",
    "\n",
    "Inside the loop, after we pick `sampled_token`, we should check if we‚Äôre done:\n",
    "\n",
    "* If `sampled_token == \"<END>\"`, we stop (and usually don‚Äôt include `<END>` in the final printed translation).\n",
    "* If `len(decoded_sentence.split())` reaches `max_decoder_seq_length`, we also stop to avoid runaway generation.\n",
    "\n",
    "Conceptually:\n",
    "\n",
    "```python\n",
    "if (sampled_token == \"<END>\") or (len(decoded_sentence.split()) > max_decoder_seq_length):\n",
    "    break\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Preparing for the Next Step\n",
    "\n",
    "If we‚Äôre not done yet, we must:\n",
    "\n",
    "1. Build the next `target_seq` containing the **newly sampled token** in one-hot form.\n",
    "2. Update `decoder_states_value` with the **new states** from this step so they carry context forward.\n",
    "\n",
    "```python\n",
    "# 1. Build the next input token for the decoder\n",
    "target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "# 2. Update states for the next iteration\n",
    "decoder_states_value = [new_decoder_hidden_state, new_decoder_cell_state]\n",
    "```\n",
    "\n",
    "On the **next iteration** of the `while` loop:\n",
    "\n",
    "* `target_seq` contains the one-hot encoding of the **previously predicted word**.\n",
    "* `decoder_states_value` carries the decoder‚Äôs updated ‚Äúmemory‚Äù so it can condition the next prediction on the entire partial sentence generated so far.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Putting It All Together\n",
    "\n",
    "Inside `decode_sequence(test_input)`:\n",
    "\n",
    "1. Use `encoder_model.predict(test_input)` to get the initial decoder states.\n",
    "2. Initialize `target_seq` with the `<START>` token.\n",
    "3. Initialize `decoded_sentence = ''`.\n",
    "4. Run a `while` loop:\n",
    "\n",
    "   * Call `decoder_model.predict(...)` with `[target_seq] + decoder_states_value`.\n",
    "   * Choose the next token using `argmax`.\n",
    "   * Append token to `decoded_sentence`.\n",
    "   * Break if `<END>` or max length reached.\n",
    "   * Update `target_seq` and `decoder_states_value`.\n",
    "5. Return `decoded_sentence` (often with `<END>` removed before printing).\n",
    "\n",
    "This loop is how the trained seq2seq model **generates text**: one token at a time, always using its own previous predictions and internal states as context, just like a small, hand-built translation engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9795222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 603ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "-\n",
      "Input sentence: We'll see.\n",
      "Decoded sentence:  . . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "-\n",
      "Input sentence: We'll see.\n",
      "Decoded sentence:  . . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "-\n",
      "Input sentence: We'll try.\n",
      "Decoded sentence:  . . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "-\n",
      "Input sentence: We've won!\n",
      "Decoded sentence:  ¬ø . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "-\n",
      "Input sentence: Well done.\n",
      "Decoded sentence:  ¬ø . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "-\n",
      "Input sentence: What's up?\n",
      "Decoded sentence:  ¬ø . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "-\n",
      "Input sentence: Who cares?\n",
      "Decoded sentence:  ¬ø ¬ø . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "-\n",
      "Input sentence: Who drove?\n",
      "Decoded sentence:  ¬ø . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "-\n",
      "Input sentence: Who drove?\n",
      "Decoded sentence:  ¬ø . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "-\n",
      "Input sentence: Who is he?\n",
      "Decoded sentence:  ¬ø . . <END>\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Sequence Decoding Function\n",
    "# -----------------------------\n",
    "def decode_sequence(test_input):\n",
    "    # Encode input sentence ‚Üí initial decoder states\n",
    "    encoder_states_value = encoder_model.predict(test_input)\n",
    "    decoder_states_value = encoder_states_value\n",
    "\n",
    "    # Prepare starting token sequence: <START>\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_features_dict[\"<START>\"]] = 1.\n",
    "\n",
    "    decoded_sentence = \"\"\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "        # Predict next token probabilities + states\n",
    "        output_tokens, new_h, new_c = decoder_model.predict(\n",
    "            [target_seq] + decoder_states_value\n",
    "        )\n",
    "\n",
    "        # Pick most probable token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "        # Stop if <END> or too long\n",
    "        if sampled_token == \"<END>\" or len(decoded_sentence.split()) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "        else:\n",
    "            # Update the target sequence with the new predicted token\n",
    "            target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "            target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "            # Update decoder states\n",
    "            decoder_states_value = [new_h, new_c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# -----------------------------\n",
    "# Try decoding the first 10 sequences\n",
    "# -----------------------------\n",
    "for seq_index in range(10):\n",
    "    test_input = encoder_input_data[seq_index : seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(test_input)\n",
    "    print(\"-\")\n",
    "    print(\"Input sentence:\", input_docs[seq_index])\n",
    "    print(\"Decoded sentence:\", decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb3325a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

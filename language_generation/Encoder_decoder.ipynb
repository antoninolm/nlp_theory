{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31f7634",
   "metadata": {},
   "source": [
    "# **Step 1: Loading the Dataset**\n",
    "\n",
    "## **INTRODUCTION**\n",
    "**Goal:** Load the English-Spanish translation pairs from a text file into memory.\n",
    "\n",
    "**Why this matters:** Before we can build any encoder-decoder model, we need data. Seq2seq models learn by seeing many pairs of sequences (English sentence → Spanish sentence). This step simply reads our training data.\n",
    "\n",
    "**Connection:** This is the foundation. Everything that follows (preprocessing, building encoder/decoder, training) depends on having these translation pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a3161b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 15:56:55.018461: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-07 15:56:55.029030: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-07 15:56:55.111377: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-12-07 15:56:55.246396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1765119415.325318   18884 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1765119415.360739   18884 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-12-07 15:56:55.594751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import re\n",
    "# Importing our translations\n",
    "data_path = \"utils/span-eng.txt\"\n",
    "# Defining lines as a list of each line\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "  lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b90a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total lines loaded: 11\n",
      "\n",
      "First 5 translation pairs:\n",
      "1. We'll see.\tDespués veremos.\n",
      "2. We'll see.\tYa veremos.\n",
      "3. We'll try.\tLo intentaremos.\n",
      "4. We've won!\t¡Hemos ganado!\n",
      "5. Well done.\tBien hecho.\n"
     ]
    }
   ],
   "source": [
    "# See how many translation pairs you have\n",
    "print(f\"Total lines loaded: {len(lines)}\")\n",
    "\n",
    "# Look at the first 5 examples\n",
    "print(\"\\nFirst 5 translation pairs:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}. {lines[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfb81bf",
   "metadata": {},
   "source": [
    "## **WHAT JUST HAPPENED?**\n",
    "\n",
    "**Before this step:** Nothing - you had no data in memory.\n",
    "\n",
    "**After this step:** \n",
    "- `lines` is now a Python list\n",
    "- Each element is a string containing one translation pair\n",
    "- Format of each line: `\"English sentence\\tSpanish sentence\"`\n",
    "- The `\\t` (tab character) separates English from Spanish\n",
    "\n",
    "**Key point:** `lines` is a **list of text elements (strings)**, where each string contains both English and Spanish separated by a tab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413612a",
   "metadata": {},
   "source": [
    "# **Step 2: Preprocessing and Tokenization**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 1, we loaded raw translation pairs into a single list called `lines`. Each element was a string containing both English and Spanish sentences separated by a tab character (`\\t`).\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We need to prepare this raw data for the encoder-decoder model by:\n",
    "1. **Separating** English and Spanish into different lists\n",
    "2. **Adding special tokens** (`<START>` and `<END>`) to Spanish sentences\n",
    "3. **Separating punctuation** from words (so the model treats `.` as its own token, not part of the word)\n",
    "4. **Building vocabularies** - collecting all unique words/tokens from both languages\n",
    "\n",
    "## **WHY THIS MATTERS FOR SEQ2SEQ:**\n",
    "- The **encoder** needs clean English sentences as input\n",
    "- The **decoder** needs Spanish sentences with special markers:\n",
    "  - `<START>` tells it \"begin generating translation\"\n",
    "  - `<END>` tells it \"stop generating, translation complete\"\n",
    "- Both need vocabularies to convert words → numbers later\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "After this step, we'll have organized data and vocabularies. The next step will be converting these words into numerical representations (indices) that the neural network can actually process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc058cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building empty lists to hold sentences\n",
    "input_docs = []\n",
    "target_docs = []\n",
    "# Building empty vocabulary sets\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "for line in lines:\n",
    "    # Input and target sentences are separated by tabs (\\t represents a line break)\n",
    "    input_doc, target_doc = line.split('\\t')\n",
    "    # Appending each input sentence to input_docs\n",
    "    # Example first line: append We'll see.\n",
    "    \n",
    "    ###CANCEEL THIS\n",
    "    input_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc))\n",
    "    ###CANCEL THIS\n",
    "    \n",
    "    input_docs.append(input_doc)\n",
    "    # Splitting words from punctuation\n",
    "    # The regex means: \"Match either a sequence of word characters (including apostrophes) OR a single punctuation mark\".\n",
    "    '''\n",
    "    The regex scans through and finds:\n",
    "\n",
    "    - \"Después\" ← matches [\\w']+ (word characters)\n",
    "    - \"veremos\" ← matches [\\w']+ (word characters)\n",
    "    - \".\" ← matches [^\\s\\w] (punctuation)\n",
    "\n",
    "    So re.findall() returns A LIST: [\"Después\", \"veremos\", \".\"]\n",
    "    Then \" \".join(...) puts spaces between them: \"Después veremos .\"\n",
    "    '''\n",
    "    target_doc = \" \".join(re.findall(r\"[\\w']+|[^\\s\\w]\", target_doc))\n",
    "    # Redefine target_doc below \n",
    "    # and append it to target_docs:\n",
    "    target_doc = \"<START> \" + target_doc + \" <END>\"\n",
    "    target_docs.append(target_doc)\n",
    "    \n",
    "    # Now we split up each sentence into words\n",
    "    # and add each unique word to our vocabulary set\n",
    "    for token in re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc):\n",
    "        # Add your code here:\n",
    "        input_tokens.add(token)\n",
    "\n",
    "    for token in target_doc.split():\n",
    "        # And here:\n",
    "        target_tokens.add(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2b00e",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Step-by-Step Flow**\n",
    "\n",
    "### **The Processing Pipeline:**\n",
    "```\n",
    "For each line in our dataset:\n",
    "\n",
    "1. SPLIT: \"We'll see.\\tDespués veremos.\"\n",
    "   ↓\n",
    "   English: \"We'll see.\"\n",
    "   Spanish: \"Después veremos.\"\n",
    "\n",
    "2. STORE ENGLISH AS-IS:\n",
    "   input_docs.append(\"We'll see.\")\n",
    "\n",
    "3. PROCESS SPANISH - Separate punctuation with regex:\n",
    "   \"Después veremos.\" \n",
    "   → regex finds: [\"Después\", \"veremos\", \".\"]\n",
    "   → join with spaces: \"Después veremos .\"\n",
    "\n",
    "4. ADD SPECIAL TOKENS TO SPANISH:\n",
    "   \"Después veremos .\"\n",
    "   → \"<START> Después veremos . <END>\"\n",
    "   \n",
    "5. STORE PROCESSED SPANISH:\n",
    "   target_docs.append(\"<START> Después veremos . <END>\")\n",
    "\n",
    "6. BUILD ENGLISH VOCABULARY:\n",
    "   - Apply regex to \"We'll see.\" → [\"We'll\", \"see\", \".\"]\n",
    "   - Add each token to input_tokens set\n",
    "\n",
    "7. BUILD SPANISH VOCABULARY:\n",
    "   - Split \"<START> Después veremos . <END>\" → [\"<START>\", \"Después\", \"veremos\", \".\", \"<END>\"]\n",
    "   - Add each token to target_tokens set\n",
    "```\n",
    "\n",
    "### **FINAL RESULT:**\n",
    "- `input_docs`: List of clean English sentences\n",
    "- `target_docs`: List of Spanish sentences with `<START>` and `<END>` markers\n",
    "- `input_tokens`: Set of all unique English words and punctuation\n",
    "- `target_tokens`: Set of all unique Spanish words, punctuation, and special tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea405d3",
   "metadata": {},
   "source": [
    "# **Step 3: Vocabulary Sizing and Sequence Length Analysis**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 2, we created:\n",
    "- `input_docs` and `target_docs` - separate lists of English and Spanish sentences\n",
    "- `input_tokens` and `target_tokens` - sets of unique words/punctuation from both languages\n",
    "\n",
    "These vocabularies are currently **unordered sets**. We need to convert them to ordered structures so we can assign consistent index numbers to each word.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're preparing critical parameters that the encoder-decoder model needs:\n",
    "\n",
    "1. **Sort vocabularies** - Convert sets to sorted lists (for consistent word-to-index mapping)\n",
    "2. **Count vocabulary sizes** - How many unique tokens in each language?\n",
    "3. **Find maximum sentence lengths** - What's the longest sentence in our dataset?\n",
    "\n",
    "## **WHY THIS MATTERS FOR SEQ2SEQ:**\n",
    "- **Vocabulary sizes** → Determine the size of the model's output layer (one neuron per possible word)\n",
    "- **Max sequence lengths** → Needed for padding (all sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2649a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "# Create num_encoder_tokens and num_decoder_tokens:\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "'''\n",
    "max_encoder_seq_length = max([len(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)) for input_doc in input_docs])\n",
    "'''\n",
    "max_encoder_seq_length = max([len(doc.split()) for doc in input_docs])\n",
    "max_decoder_seq_length = max([len(doc.split()) for doc in target_docs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea699e5",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Step-by-Step Flow**\n",
    "\n",
    "### **The Processing Pipeline:**\n",
    "```\n",
    "STEP 1: Convert Sets to Sorted Lists\n",
    "--------------------------------\n",
    "Before: input_tokens = {'see', 'We', 'try', ...}  (unordered set)\n",
    "After:  input_tokens = ['!', '.', '?', 'We', 'see', 'try', ...]  (sorted list)\n",
    "\n",
    "Why? Sets have no order - each time you run the code, words appear in random order.\n",
    "Sorting alphabetically ensures consistency: 'hello' always gets the same position.\n",
    "\n",
    "STEP 2: Count Vocabulary Sizes\n",
    "--------------------------------\n",
    "num_encoder_tokens = len(input_tokens)  # e.g., 50 unique English words\n",
    "num_decoder_tokens = len(target_tokens)  # e.g., 60 unique Spanish words\n",
    "\n",
    "Why? The model's output layer needs one neuron per possible word.\n",
    "If you have 60 Spanish words, the decoder outputs 60 probabilities (one per word).\n",
    "\n",
    "STEP 3: Find Maximum Sentence Lengths\n",
    "--------------------------------\n",
    "For each sentence in input_docs:\n",
    "  - Tokenize it with regex\n",
    "  - Count how many tokens\n",
    "  - Keep track of the maximum\n",
    "\n",
    "Example:\n",
    "  \"We'll see.\" → [\"We'll\", \"see\", \".\"] → 3 tokens\n",
    "  \"Who is he?\" → [\"Who\", \"is\", \"he\", \"?\"] → 4 tokens\n",
    "  max_encoder_seq_length = 4\n",
    "\n",
    "Why? Neural networks need fixed-size inputs. Later, we'll pad shorter sentences\n",
    "with zeros to match the longest one (3-token sentence becomes [token, token, token, 0]).\n",
    "```\n",
    "\n",
    "### **FINAL RESULT:**\n",
    "- `input_tokens`: Sorted list of unique English tokens\n",
    "- `target_tokens`: Sorted list of unique Spanish tokens (including `<START>`, `<END>`)\n",
    "- `num_encoder_tokens`: Integer - size of English vocabulary\n",
    "- `num_decoder_tokens`: Integer - size of Spanish vocabulary\n",
    "- `max_encoder_seq_length`: Integer - longest English sentence in tokens\n",
    "- `max_decoder_seq_length`: Integer - longest Spanish sentence in tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac41fde",
   "metadata": {},
   "source": [
    "# **Step 4: Creating Word-to-Index Mappings (Tokenization Dictionaries)**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 3, we created sorted lists of unique tokens:\n",
    "- `input_tokens` - sorted list of English words/punctuation\n",
    "- `target_tokens` - sorted list of Spanish words/punctuation (including `<START>`, `<END>`)\n",
    "\n",
    "These are still just **words** (strings). Neural networks can't process text - they need **numbers**.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're creating **dictionaries** that map between words and numbers:\n",
    "\n",
    "1. **Forward mappings** (word → index): Convert text to numbers for model input\n",
    "   - `input_features_dict`: English word → number\n",
    "   - `target_features_dict`: Spanish word → number\n",
    "\n",
    "2. **Reverse mappings** (index → word): Convert numbers back to text for human reading\n",
    "   - `reverse_input_features_dict`: number → English word\n",
    "   - `reverse_target_features_dict`: number → Spanish word\n",
    "\n",
    "## **WHY THIS MATTERS FOR SEQ2SEQ:**\n",
    "- **Training phase**: Convert \"We'll see .\" → `[45, 89, 12]` to feed into encoder\n",
    "- **Inference phase**: Convert decoder output `[23, 56, 78]` → \"Después veremos .\" for humans to read\n",
    "- **Consistency**: Because we sorted in Step 3, \"hello\" always gets the same index (e.g., 45) every time\n",
    "\n",
    "## **THE PROCESS:**Text → Numbers (forward dict) → Model → Numbers → Text (reverse dict)\n",
    "\"hello\" → 45 → [neural network processing] → 23 → \"hola\"\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "With these mappings in place, we'll create the actual training data - converting all our sentences into numerical arrays that the encoder-decoder can process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "545a9dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 11\n",
      "Number of unique input tokens: 18\n",
      "Number of unique output tokens: 27\n",
      "Max sequence length for inputs: 4\n",
      "Max sequence length for outputs: 8\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('Number of samples:', len(input_docs))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "# Remember, input_tokens is a sorted list: ['!', '.', '?', 'We', 'see', ...]\n",
    "# enumerate gives you: (index, value) pairs, so for more utems in the list, it gives you a list of TUPLES\n",
    "# Output:\n",
    "# 0 !\n",
    "# 1 .\n",
    "# 2 ?\n",
    "# 3 We\n",
    "# 4 see\n",
    "# ...\n",
    "# So this creates a dictionary where the keys are the tokens, while the values arethe indexes \n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "\n",
    "# Build out target_features_dict:\n",
    "target_features_dict = dict([(token, i) for i, token in enumerate(target_tokens)])\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for token, i in input_features_dict.items())\n",
    "# Build out reverse_target_features_dict:\n",
    "reverse_target_features_dict = dict([(i, token) for token, i in target_features_dict.items()])\n",
    "\n",
    "notes_= '''\n",
    "APPROACH 2,simpler:\n",
    "First create the forward dict\n",
    "input_features_dict = dict(\n",
    "    [(token, i) for i, token in enumerate(input_tokens)])\n",
    "\n",
    "Then flip it to create reverse dict\n",
    "reverse_input_features_dict = dict(\n",
    "    (i, token) for i, token in enumerate(input_tokens))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5ca16",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Step-by-Step Flow**\n",
    "\n",
    "### **The Processing Pipeline:**\n",
    "```\n",
    "STEP 1: Print Summary Statistics\n",
    "--------------------------------\n",
    "Display key parameters:\n",
    "- Total number of translation pairs\n",
    "- Vocabulary sizes for English and Spanish\n",
    "- Maximum sentence lengths\n",
    "\n",
    "This gives us a quick sanity check of our data.\n",
    "\n",
    "STEP 2: Create Forward Mapping for English\n",
    "--------------------------------\n",
    "input_tokens = ['!', '.', '?', 'We', 'see', ...]  (sorted list)\n",
    "                ↓ enumerate() yields (0, '!'), (1, '.'), (2, '?'), ...\n",
    "                ↓ dict comprehension flips to (token, index)\n",
    "input_features_dict = {'!': 0, '.': 1, '?': 2, 'We': 3, 'see': 4, ...}\n",
    "\n",
    "Purpose: Look up any English word and get its index number\n",
    "Example: input_features_dict['We'] → 3\n",
    "\n",
    "STEP 3: Create Forward Mapping for Spanish\n",
    "--------------------------------\n",
    "target_tokens = ['<START>', '<END>', '!', '.', 'Después', ...]\n",
    "                ↓ enumerate() yields (0, '<START>'), (1, '<END>'), ...\n",
    "                ↓ dict comprehension flips to (token, index)\n",
    "target_features_dict = {'<START>': 0, '<END>': 1, '!': 2, '.': 3, 'Después': 4, ...}\n",
    "\n",
    "Purpose: Look up any Spanish word and get its index number\n",
    "Example: target_features_dict['Después'] → 4\n",
    "\n",
    "STEP 4: Create Reverse Mapping for English\n",
    "--------------------------------\n",
    "input_features_dict.items() = [('!', 0), ('.', 1), ('We', 3), ...]\n",
    "                ↓ dict comprehension flips to (index, token)\n",
    "reverse_input_features_dict = {0: '!', 1: '.', 3: 'We', ...}\n",
    "\n",
    "Purpose: Convert index numbers back to English words\n",
    "Example: reverse_input_features_dict[3] → 'We'\n",
    "\n",
    "STEP 5: Create Reverse Mapping for Spanish\n",
    "--------------------------------\n",
    "target_features_dict.items() = [('<START>', 0), ('<END>', 1), ('Después', 4), ...]\n",
    "                ↓ dict comprehension flips to (index, token)\n",
    "reverse_target_features_dict = {0: '<START>', 1: '<END>', 4: 'Después', ...}\n",
    "\n",
    "Purpose: Convert index numbers back to Spanish words\n",
    "Example: reverse_target_features_dict[4] → 'Después'\n",
    "```\n",
    "\n",
    "### **COMPLETE WORKFLOW - TEXT TO NUMBERS AND BACK:**\n",
    "```\n",
    "ENCODING (Training):\n",
    "\"We'll see .\" \n",
    "    → tokenize: ['We', 'see', '.']\n",
    "    → forward dict: [3, 4, 1]\n",
    "    → feed to encoder\n",
    "\n",
    "DECODING (Inference):\n",
    "decoder output: [4, 5, 3]\n",
    "    → reverse dict: ['Después', 'veremos', '.']\n",
    "    → join: \"Después veremos .\"\n",
    "    → show to human\n",
    "```\n",
    "\n",
    "### **FINAL RESULT:**\n",
    "We now have 4 dictionaries that allow bidirectional conversion between words and numbers:\n",
    "- `input_features_dict`: English word → number\n",
    "- `target_features_dict`: Spanish word → number  \n",
    "- `reverse_input_features_dict`: number → English word\n",
    "- `reverse_target_features_dict`: number → Spanish word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637e69ed",
   "metadata": {},
   "source": [
    "# **Step 5: Creating Empty 3D Training Matrices**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 4, we created four dictionaries that map between words and numbers:\n",
    "- `input_features_dict` and `reverse_input_features_dict` (English)\n",
    "- `target_features_dict` and `reverse_target_features_dict` (Spanish)\n",
    "\n",
    "We can now convert individual words to numbers, but we need **entire datasets** in numerical form.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're creating three massive 3D NumPy arrays filled with zeros. These will serve as containers for all our training data:\n",
    "\n",
    "1. **encoder_input_data** - English sentences that go into the encoder\n",
    "2. **decoder_input_data** - Spanish sentences that the decoder sees as input\n",
    "3. **decoder_target_data** - Spanish sentences that the decoder should output (ground truth)\n",
    "\n",
    "## **WHY THREE DIMENSIONS?**\n",
    "\n",
    "Each matrix has the shape: **(number of sentences, max sequence length, vocabulary size)**\n",
    "\n",
    "This 3D structure allows us to represent:\n",
    "- **Dimension 1:** Which sentence from our dataset?\n",
    "- **Dimension 2:** Which position in that sentence? (1st word, 2nd word, etc.)\n",
    "- **Dimension 3:** Which word is it? (one-hot encoded vector)\n",
    "\n",
    "## **WHY WE NEED THREE SEPARATE MATRICES:**\n",
    "\n",
    "The encoder-decoder architecture requires:\n",
    "- **Encoder input:** English sentences to encode into meaning\n",
    "- **Decoder input:** Spanish sentences starting with `<START>` token\n",
    "- **Decoder target:** Spanish sentences ending with `<END>` token (shifted by one position)\n",
    "\n",
    "The decoder learns by seeing the Spanish translation with `<START>` and trying to output the translation with `<END>`.\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "After creating these empty matrices, we'll fill them with actual one-hot encoded words from our sentences. Right now they're just scaffolding - all zeros waiting to be populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69528c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here's the first item in the encoder input matrix:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      "\n",
      "The number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\n"
     ]
    }
   ],
   "source": [
    "encoder_input_data = np.zeros(\n",
    "    (len(input_docs), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "  \n",
    "print(\"\\nHere's the first item in the encoder input matrix:\\n\", encoder_input_data[0], \"\\n\\nThe number of columns should match the number of unique input tokens and the number of rows should match the maximum sequence length for input sentences.\")\n",
    "\n",
    "# Build out the decoder_input_data matrix:\n",
    "decoder_input_data = np.zeros(\n",
    "  (len(input_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "# Build out the decoder_target_data matrix:\n",
    "decoder_target_data = np.zeros(\n",
    "  (len(target_docs), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448aad89",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Step-by-Step Flow**\n",
    "\n",
    "### **The Processing Pipeline:**\n",
    "```\n",
    "STEP 1: Create Encoder Input Matrix\n",
    "------------------------------------\n",
    "Shape: (len(input_docs), max_encoder_seq_length, num_encoder_tokens)\n",
    "Example: (11 sentences, 4 time steps, 50 English words)\n",
    "\n",
    "Result: A 3D array filled with zeros\n",
    "Purpose: Will hold one-hot encoded English sentences\n",
    "\n",
    "STEP 2: Create Decoder Input Matrix  \n",
    "------------------------------------\n",
    "Shape: (len(input_docs), max_decoder_seq_length, num_decoder_tokens)\n",
    "Example: (11 sentences, 6 time steps, 60 Spanish words)\n",
    "\n",
    "Result: A 3D array filled with zeros\n",
    "Purpose: Will hold Spanish sentences starting with <START>\n",
    "\n",
    "STEP 3: Create Decoder Target Matrix\n",
    "------------------------------------\n",
    "Shape: (len(target_docs), max_decoder_seq_length, num_decoder_tokens)\n",
    "Example: (11 sentences, 6 time steps, 60 Spanish words)\n",
    "\n",
    "Result: A 3D array filled with zeros\n",
    "Purpose: Will hold Spanish sentences ending with <END> (what decoder should output)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **VISUALIZING THE 3D MATRIX STRUCTURE**\n",
    "\n",
    "### **Understanding the Dimensions:**\n",
    "\n",
    "Let's use concrete numbers from your dataset:\n",
    "- You have **11 sentences**\n",
    "- Longest English sentence: **4 tokens**\n",
    "- English vocabulary: **50 unique words**\n",
    "\n",
    "So `encoder_input_data` has shape **(11, 4, 50)**\n",
    "\n",
    "---\n",
    "\n",
    "### **Think of it as a stack of 2D matrices:**\n",
    "```\n",
    "encoder_input_data = [\n",
    "    sentence_0,  ← 2D matrix (4 rows × 50 columns)\n",
    "    sentence_1,  ← 2D matrix (4 rows × 50 columns)\n",
    "    sentence_2,  ← 2D matrix (4 rows × 50 columns)\n",
    "    ...\n",
    "    sentence_10  ← 2D matrix (4 rows × 50 columns)\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Zooming into ONE sentence (2D matrix):**\n",
    "\n",
    "Let's say sentence 0 is \"We'll see .\"\n",
    "\n",
    "**After tokenization:**\n",
    "- Position 0: \"We'll\" (index 45 in vocabulary)\n",
    "- Position 1: \"see\" (index 48 in vocabulary)\n",
    "- Position 2: \".\" (index 1 in vocabulary)\n",
    "- Position 3: (padding - will stay all zeros)\n",
    "\n",
    "**The matrix for this sentence (4 × 50):**\n",
    "```\n",
    "                 Word_0  Word_1  ...  Word_45  ...  Word_48  ...  Word_49\n",
    "                   !       .            We'll        see\n",
    "Position 0:       [0       0     ...     1      ...    0     ...    0    ]  ← \"We'll\"\n",
    "Position 1:       [0       0     ...     0      ...    1     ...    0    ]  ← \"see\"\n",
    "Position 2:       [0       1     ...     0      ...    0     ...    0    ]  ← \".\"\n",
    "Position 3:       [0       0     ...     0      ...    0     ...    0    ]  ← padding\n",
    "```\n",
    "\n",
    "**Key points:**\n",
    "- Each row = one word position in the sentence\n",
    "- Each row has exactly ONE cell with value 1 (the word's index)\n",
    "- All other cells in that row are 0\n",
    "- This is called **one-hot encoding**\n",
    "\n",
    "---\n",
    "\n",
    "### **Example: One-Hot Encoding Breakdown**\n",
    "\n",
    "**Vocabulary (simplified):**\n",
    "```\n",
    "Index 0: !\n",
    "Index 1: .\n",
    "Index 2: ?\n",
    "Index 3: We\n",
    "Index 4: see\n",
    "Index 5: try\n",
    "...\n",
    "Index 49: (last word)\n",
    "```\n",
    "\n",
    "**The word \"see\" (index 4) becomes:**\n",
    "```\n",
    "[0, 0, 0, 0, 1, 0, 0, 0, ..., 0]\n",
    "             ↑\n",
    "        Position 4 = 1\n",
    "        All others = 0\n",
    "```\n",
    "\n",
    "This vector has length 50 (same as vocabulary size).\n",
    "\n",
    "---\n",
    "\n",
    "### **The Complete 3D Structure:**\n",
    "```\n",
    "DIMENSION 1 (Sentence selector):\n",
    "encoder_input_data[0]  → \"We'll see .\"\n",
    "encoder_input_data[1]  → \"We'll try .\"\n",
    "encoder_input_data[2]  → \"Who is he ?\"\n",
    "...\n",
    "\n",
    "DIMENSION 2 (Word position in sentence):\n",
    "encoder_input_data[0][0]  → First word of first sentence: \"We'll\"\n",
    "encoder_input_data[0][1]  → Second word of first sentence: \"see\"\n",
    "encoder_input_data[0][2]  → Third word of first sentence: \".\"\n",
    "\n",
    "DIMENSION 3 (One-hot vector for the word):\n",
    "encoder_input_data[0][0][45]  → This cell = 1 (because \"We'll\" is at index 45)\n",
    "encoder_input_data[0][0][0]   → This cell = 0\n",
    "encoder_input_data[0][0][1]   → This cell = 0\n",
    "... (all other positions are 0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why This Structure?**\n",
    "\n",
    "**Neural networks need:**\n",
    "1. **Fixed-size inputs** → All sentences padded to same length (max_encoder_seq_length)\n",
    "2. **Numerical data** → Words converted to numbers via one-hot encoding\n",
    "3. **Batch processing** → Multiple sentences stacked in dimension 0\n",
    "\n",
    "**The 3D shape enables:**\n",
    "- Processing all 11 sentences at once (batch training)\n",
    "- Handling variable-length sentences (padding with zeros)\n",
    "- Representing each word as a unique vector (one-hot encoding)\n",
    "\n",
    "---\n",
    "\n",
    "### **Current State: All Zeros**\n",
    "\n",
    "Right now, all three matrices look like this:\n",
    "```\n",
    "encoder_input_data[0] = \n",
    "[[0, 0, 0, ..., 0],\n",
    " [0, 0, 0, ..., 0],\n",
    " [0, 0, 0, ..., 0],\n",
    " [0, 0, 0, ..., 0]]\n",
    "```\n",
    "\n",
    "**Next step:** Fill these zeros with actual one-hot encoded words from your sentences!\n",
    "\n",
    "---\n",
    "\n",
    "### **WHAT CHANGED FROM STEP 4:**\n",
    "\n",
    "| Aspect | Step 4 | Step 5 |\n",
    "|--------|--------|--------|\n",
    "| **Data structure** | Dictionaries (word ↔ index mappings) | 3D NumPy arrays (empty containers) |\n",
    "| **Content** | Lookup tables for individual words | Space allocated for entire dataset |\n",
    "| **Ready for training?** | No - need actual numerical arrays | Almost - containers ready, need to fill them |\n",
    "| **Memory allocated?** | Minimal (just dictionaries) | Yes - large arrays allocated in RAM |\n",
    "\n",
    "✅ **Ready for Step 6 - Filling the matrices with actual data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126c87ed",
   "metadata": {},
   "source": [
    "# **Step 6: Filling the Matrices with One-Hot Encoded Data**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 5, we created three empty 3D NumPy arrays:\n",
    "- `encoder_input_data` - shape: (num_sentences, max_encoder_seq_length, num_encoder_tokens)\n",
    "- `decoder_input_data` - shape: (num_sentences, max_decoder_seq_length, num_decoder_tokens)\n",
    "- `decoder_target_data` - shape: (num_sentences, max_decoder_seq_length, num_decoder_tokens)\n",
    "\n",
    "These were filled entirely with zeros - just empty scaffolding waiting for actual data.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're converting our text sentences into one-hot encoded vectors and filling these matrices with actual training data. This is where the transformation from human-readable text to machine-processable numbers is completed.\n",
    "\n",
    "**The process:**\n",
    "1. Loop through each sentence pair (English + Spanish)\n",
    "2. For each word in the English sentence → create one-hot vector → place in `encoder_input_data`\n",
    "3. For each word in the Spanish sentence → create one-hot vector → place in `decoder_input_data`\n",
    "4. For each word in the Spanish sentence (shifted by 1) → create one-hot vector → place in `decoder_target_data`\n",
    "\n",
    "## **KEY CONCEPT: The Decoder Input/Target Shift**\n",
    "\n",
    "The decoder learns by seeing the correct previous word and predicting the next word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13086629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"We'll see .\", \"We'll see .\", \"We'll try .\", \"We've won !\", 'Well done .', \"What's up ?\", 'Who cares ?', 'Who drove ?', 'Who drove ?', 'Who is he ?', 'Who is it ?']\n"
     ]
    }
   ],
   "source": [
    "print(input_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8031b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START> Después veremos . <END>', '<START> Ya veremos . <END>', '<START> Lo intentaremos . <END>', '<START> ¡ Hemos ganado ! <END>', '<START> Bien hecho . <END>', '<START> ¿ Qué hay ? <END>', '<START> ¿ A quién le importa ? <END>', '<START> ¿ Quién condujo ? <END>', '<START> ¿ Quién conducía ? <END>', '<START> ¿ Quién es él ? <END>', '<START> ¿ Quién es ? <END>']\n"
     ]
    }
   ],
   "source": [
    "print(target_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a59e7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input timestep & token: 0 We'll\n",
      "3\n",
      "Encoder input timestep & token: 1 see\n",
      "14\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Después\n",
      "7\n",
      "Decoder target timestep: 1 Después\n",
      "Decoder input timestep & token: 2 veremos\n",
      "23\n",
      "Decoder target timestep: 2 veremos\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3 .\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4 <END>\n",
      "Encoder input timestep & token: 0 We'll\n",
      "3\n",
      "Encoder input timestep & token: 1 see\n",
      "14\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Ya\n",
      "12\n",
      "Decoder target timestep: 1 Ya\n",
      "Decoder input timestep & token: 2 veremos\n",
      "23\n",
      "Decoder target timestep: 2 veremos\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3 .\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4 <END>\n",
      "Encoder input timestep & token: 0 We'll\n",
      "3\n",
      "Encoder input timestep & token: 1 try\n",
      "15\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Lo\n",
      "9\n",
      "Decoder target timestep: 1 Lo\n",
      "Decoder input timestep & token: 2 intentaremos\n",
      "20\n",
      "Decoder target timestep: 2 intentaremos\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3 .\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4 <END>\n",
      "Encoder input timestep & token: 0 We've\n",
      "4\n",
      "Encoder input timestep & token: 1 won\n",
      "17\n",
      "Encoder input timestep & token: 2 !\n",
      "0\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¡\n",
      "24\n",
      "Decoder target timestep: 1 ¡\n",
      "Decoder input timestep & token: 2 Hemos\n",
      "8\n",
      "Decoder target timestep: 2 Hemos\n",
      "Decoder input timestep & token: 3 ganado\n",
      "16\n",
      "Decoder target timestep: 3 ganado\n",
      "Decoder input timestep & token: 4 !\n",
      "0\n",
      "Decoder target timestep: 4 !\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5 <END>\n",
      "Encoder input timestep & token: 0 Well\n",
      "5\n",
      "Encoder input timestep & token: 1 done\n",
      "9\n",
      "Encoder input timestep & token: 2 .\n",
      "1\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 Bien\n",
      "6\n",
      "Decoder target timestep: 1 Bien\n",
      "Decoder input timestep & token: 2 hecho\n",
      "18\n",
      "Decoder target timestep: 2 hecho\n",
      "Decoder input timestep & token: 3 .\n",
      "1\n",
      "Decoder target timestep: 3 .\n",
      "Decoder input timestep & token: 4 <END>\n",
      "2\n",
      "Decoder target timestep: 4 <END>\n",
      "Encoder input timestep & token: 0 What's\n",
      "6\n",
      "Encoder input timestep & token: 1 up\n",
      "16\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¿\n",
      "25\n",
      "Decoder target timestep: 1 ¿\n",
      "Decoder input timestep & token: 2 Qué\n",
      "11\n",
      "Decoder target timestep: 2 Qué\n",
      "Decoder input timestep & token: 3 hay\n",
      "17\n",
      "Decoder target timestep: 3 hay\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4 ?\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5 <END>\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 cares\n",
      "8\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¿\n",
      "25\n",
      "Decoder target timestep: 1 ¿\n",
      "Decoder input timestep & token: 2 A\n",
      "5\n",
      "Decoder target timestep: 2 A\n",
      "Decoder input timestep & token: 3 quién\n",
      "22\n",
      "Decoder target timestep: 3 quién\n",
      "Decoder input timestep & token: 4 le\n",
      "21\n",
      "Decoder target timestep: 4 le\n",
      "Decoder input timestep & token: 5 importa\n",
      "19\n",
      "Decoder target timestep: 5 importa\n",
      "Decoder input timestep & token: 6 ?\n",
      "4\n",
      "Decoder target timestep: 6 ?\n",
      "Decoder input timestep & token: 7 <END>\n",
      "2\n",
      "Decoder target timestep: 7 <END>\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 drove\n",
      "10\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¿\n",
      "25\n",
      "Decoder target timestep: 1 ¿\n",
      "Decoder input timestep & token: 2 Quién\n",
      "10\n",
      "Decoder target timestep: 2 Quién\n",
      "Decoder input timestep & token: 3 condujo\n",
      "14\n",
      "Decoder target timestep: 3 condujo\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4 ?\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5 <END>\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 drove\n",
      "10\n",
      "Encoder input timestep & token: 2 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¿\n",
      "25\n",
      "Decoder target timestep: 1 ¿\n",
      "Decoder input timestep & token: 2 Quién\n",
      "10\n",
      "Decoder target timestep: 2 Quién\n",
      "Decoder input timestep & token: 3 conducía\n",
      "13\n",
      "Decoder target timestep: 3 conducía\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4 ?\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5 <END>\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 is\n",
      "12\n",
      "Encoder input timestep & token: 2 he\n",
      "11\n",
      "Encoder input timestep & token: 3 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¿\n",
      "25\n",
      "Decoder target timestep: 1 ¿\n",
      "Decoder input timestep & token: 2 Quién\n",
      "10\n",
      "Decoder target timestep: 2 Quién\n",
      "Decoder input timestep & token: 3 es\n",
      "15\n",
      "Decoder target timestep: 3 es\n",
      "Decoder input timestep & token: 4 él\n",
      "26\n",
      "Decoder target timestep: 4 él\n",
      "Decoder input timestep & token: 5 ?\n",
      "4\n",
      "Decoder target timestep: 5 ?\n",
      "Decoder input timestep & token: 6 <END>\n",
      "2\n",
      "Decoder target timestep: 6 <END>\n",
      "Encoder input timestep & token: 0 Who\n",
      "7\n",
      "Encoder input timestep & token: 1 is\n",
      "12\n",
      "Encoder input timestep & token: 2 it\n",
      "13\n",
      "Encoder input timestep & token: 3 ?\n",
      "2\n",
      "Decoder input timestep & token: 0 <START>\n",
      "3\n",
      "Decoder input timestep & token: 1 ¿\n",
      "25\n",
      "Decoder target timestep: 1 ¿\n",
      "Decoder input timestep & token: 2 Quién\n",
      "10\n",
      "Decoder target timestep: 2 Quién\n",
      "Decoder input timestep & token: 3 es\n",
      "15\n",
      "Decoder target timestep: 3 es\n",
      "Decoder input timestep & token: 4 ?\n",
      "4\n",
      "Decoder target timestep: 4 ?\n",
      "Decoder input timestep & token: 5 <END>\n",
      "2\n",
      "Decoder target timestep: 5 <END>\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "zip() takes two (or more) lists and pairs up their elements into tuples.\n",
    "What enumerate(zip(input_docs, target_docs)) produces:\n",
    "[\n",
    "    (0, (\"We'll see.\", \"<START> Después veremos . <END>\")),\n",
    "    (1, (\"We'll try.\", \"<START> Lo intentaremos . <END>\")),\n",
    "    (2, (\"We've won!\", \"<START> ¡ Hemos ganado ! <END>\")),\n",
    "    ...\n",
    "]\n",
    "'''\n",
    "for line, (input_doc, target_doc) in enumerate(zip(input_docs, target_docs)):\n",
    "    '''\n",
    "    So now we have 3 separate entities: \n",
    "    - line: the sentence index (which sentence number we're processing: 0, 1, 2, ...)\n",
    "    - input_doc: the actual English sentence string at that index\n",
    "    - target_doc: the actual Spanish sentence string at that index\n",
    "    \n",
    "    Starting at line = 0, we have:\n",
    "        - input_doc = \"We'll see.\"\n",
    "        - target_doc = \"<START> Después veremos . <END>\"\n",
    "    '''\n",
    "    \n",
    "    for timestep, token in enumerate(input_doc.split()):\n",
    "    # for timestep, token in enumerate(re.findall(r\"[\\w']+|[^\\s\\w]\", input_doc)):\n",
    "        '''\n",
    "        This produces tuples that enumerate each token of the input_doc currently being looped.\n",
    "        So, for \"We'll see.\", it gives:\n",
    "        (0, \"We'll\")\n",
    "        (1, \"see\")\n",
    "        (2, \".\")\n",
    "        \n",
    "        timestep = the position of the word in the sentence\n",
    "        token = the actual word/punctuation string\n",
    "        '''\n",
    "        print(\"Encoder input timestep & token:\", timestep, token)\n",
    "        # We need to recover the index of the token from the vocabulary dictionary,\n",
    "        # so we can place the 1 at the correct position in the one-hot vector\n",
    "        print(input_features_dict[token])\n",
    "        # Assign 1 for the current sentence (line), word position (timestep), \n",
    "        # and word index in encoder_input_data:\n",
    "        encoder_input_data[line, timestep, input_features_dict[token]] = 1.\n",
    "    \n",
    "    for timestep, token in enumerate(target_doc.split()):\n",
    "        '''\n",
    "        Same as what we did above, but now we fill decoder_input_data.\n",
    "        Only difference: target_doc tokens are already separated by spaces,\n",
    "        so .split() produces a list of the tokens without needing regex.\n",
    "        \n",
    "        For \"<START> Después veremos . <END>\", this gives:\n",
    "        (0, \"<START>\")\n",
    "        (1, \"Después\")\n",
    "        (2, \"veremos\")\n",
    "        (3, \".\")\n",
    "        (4, \"<END>\")\n",
    "        '''\n",
    "        print(\"Decoder input timestep & token:\", timestep, token)\n",
    "        # Assign 1 for the current sentence (line), word position (timestep),\n",
    "        # and word index in decoder_input_data:\n",
    "        print(target_features_dict[token])\n",
    "        decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "        \n",
    "        if timestep > 0:\n",
    "            '''\n",
    "            decoder_target_data is shifted left by 1 timestep (ahead), meaning:\n",
    "            - decoder_input_data at position 0 has \"<START>\"\n",
    "            - decoder_target_data at position 0 has \"Después\" (what should be output when seeing <START>)\n",
    "            - decoder_input_data at position 1 has \"Después\"\n",
    "            - decoder_target_data at position 1 has \"veremos\" (what should be output when seeing Después)\n",
    "            \n",
    "            The if timestep > 0 skips the <START> token (timestep 0), because <START> \n",
    "            should never appear in the target output - it's only an input signal.\n",
    "            '''\n",
    "            print(\"Decoder target timestep:\", timestep, token)\n",
    "            # Assign 1 for the current sentence (line), shifted position (timestep-1),\n",
    "            # and word index in decoder_target_data:\n",
    "            decoder_target_data[line, timestep-1, target_features_dict[token]] = 1.\n",
    "            # We use timestep-1 to shift everything left by one position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfacbeb",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Step-by-Step Flow**\n",
    "\n",
    "### **The Processing Pipeline:**\n",
    "```\n",
    "STEP 1: Pair Up Sentences\n",
    "--------------------------\n",
    "Use zip() to pair English and Spanish sentences:\n",
    "(\"We'll see .\", \"<START> Después veremos . <END>\")\n",
    "\n",
    "Use enumerate() to add sentence indices:\n",
    "(0, (\"We'll see .\", \"<START> Después veremos . <END>\"))\n",
    "\n",
    "STEP 2: Fill Encoder Input Data\n",
    "--------------------------------\n",
    "For each English sentence:\n",
    "  - Split into tokens: [\"We'll\", \"see\", \".\"]\n",
    "  - For each token:\n",
    "    * Look up its index in input_features_dict\n",
    "    * Set encoder_input_data[sentence_idx, word_position, word_index] = 1\n",
    "    * This creates a one-hot encoded vector\n",
    "\n",
    "STEP 3: Fill Decoder Input Data\n",
    "--------------------------------\n",
    "For each Spanish sentence:\n",
    "  - Split into tokens: [\"<START>\", \"Después\", \"veremos\", \".\", \"<END>\"]\n",
    "  - For each token:\n",
    "    * Look up its index in target_features_dict\n",
    "    * Set decoder_input_data[sentence_idx, word_position, word_index] = 1\n",
    "    * This creates a one-hot encoded vector\n",
    "\n",
    "STEP 4: Fill Decoder Target Data (Shifted!)\n",
    "--------------------------------------------\n",
    "For each Spanish sentence (skipping <START>):\n",
    "  - Start from timestep 1 (skip timestep 0 which is <START>)\n",
    "  - For each token after <START>:\n",
    "    * Place it at position (timestep - 1) in decoder_target_data\n",
    "    * This shifts everything left by one position\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **VISUALIZING THE ONE-HOT ENCODING**\n",
    "\n",
    "### **Example Sentence: \"We'll see .\"**\n",
    "\n",
    "**After tokenization (from Step 2):**\n",
    "```\n",
    "[\"We'll\", \"see\", \".\"]\n",
    "```\n",
    "\n",
    "**Looking up indices in input_features_dict:**\n",
    "```\n",
    "\"We'll\" → index 3\n",
    "\"see\"   → index 14\n",
    "\".\"     → index 1\n",
    "```\n",
    "\n",
    "**Filling encoder_input_data[0] (first sentence):**\n",
    "```\n",
    "Position 0 (timestep 0, token \"We'll\"):\n",
    "encoder_input_data[0, 0, :] = [0, 0, 0, 1, 0, 0, ..., 0]\n",
    "                                        ↑\n",
    "                                    index 3 = 1\n",
    "\n",
    "Position 1 (timestep 1, token \"see\"):\n",
    "encoder_input_data[0, 1, :] = [0, 0, 0, 0, ..., 1, ..., 0]\n",
    "                                              ↑\n",
    "                                          index 14 = 1\n",
    "\n",
    "Position 2 (timestep 2, token \".\"):\n",
    "encoder_input_data[0, 2, :] = [0, 1, 0, 0, 0, ..., 0]\n",
    "                                  ↑\n",
    "                              index 1 = 1\n",
    "\n",
    "Position 3 (padding):\n",
    "encoder_input_data[0, 3, :] = [0, 0, 0, 0, ..., 0]  (all zeros)\n",
    "```\n",
    "\n",
    "**Each row is a one-hot vector:** exactly one position is 1, all others are 0.\n",
    "\n",
    "---\n",
    "\n",
    "## **VISUALIZING THE DECODER SHIFT**\n",
    "\n",
    "### **Example: \"<START> Después veremos . <END>\"**\n",
    "\n",
    "**Token indices:**\n",
    "```\n",
    "\"<START>\" → 3\n",
    "\"Después\" → 7\n",
    "\"veremos\" → 23\n",
    "\".\"       → 1\n",
    "\"<END>\"   → 2\n",
    "```\n",
    "\n",
    "### **decoder_input_data (what decoder sees):**\n",
    "```\n",
    "Position 0: <START>  → decoder_input_data[0, 0, 3] = 1\n",
    "Position 1: Después  → decoder_input_data[0, 1, 7] = 1\n",
    "Position 2: veremos  → decoder_input_data[0, 2, 23] = 1\n",
    "Position 3: .        → decoder_input_data[0, 3, 1] = 1\n",
    "Position 4: <END>    → decoder_input_data[0, 4, 2] = 1\n",
    "```\n",
    "\n",
    "### **decoder_target_data (what decoder should output - SHIFTED!):**\n",
    "```\n",
    "Position 0: Después  → decoder_target_data[0, 0, 7] = 1   ← from timestep 1\n",
    "Position 1: veremos  → decoder_target_data[0, 1, 23] = 1  ← from timestep 2\n",
    "Position 2: .        → decoder_target_data[0, 2, 1] = 1   ← from timestep 3\n",
    "Position 3: <END>    → decoder_target_data[0, 3, 2] = 1   ← from timestep 4\n",
    "Position 4: (padding) → decoder_target_data[0, 4, :] = all zeros\n",
    "```\n",
    "\n",
    "**Notice:** `<START>` appears in input but NOT in target!\n",
    "\n",
    "---\n",
    "\n",
    "## **THE COMPLETE ALIGNMENT**\n",
    "\n",
    "### **Training Example for the Decoder:**\n",
    "```\n",
    "TIME    DECODER INPUT          DECODER TARGET (what it should output)\n",
    "  0     <START>          →     Después\n",
    "  1     Después          →     veremos\n",
    "  2     veremos          →     .\n",
    "  3     .                →     <END>\n",
    "  4     <END>            →     (nothing - padding)\n",
    "```\n",
    "\n",
    "**This is how the decoder learns:**\n",
    "- \"When I see `<START>`, I should output `Después`\"\n",
    "- \"When I see `Después`, I should output `veremos`\"\n",
    "- \"When I see `veremos`, I should output `.`\"\n",
    "- \"When I see `.`, I should output `<END>`\"\n",
    "\n",
    "During training, the model compares its actual output with `decoder_target_data` and adjusts its weights to minimize the difference.\n",
    "\n",
    "---\n",
    "\n",
    "## **CODE WALKTHROUGH: The `if timestep > 0` Condition**\n",
    "```python\n",
    "for timestep, token in enumerate(target_doc.split()):\n",
    "    # Always fill decoder_input_data\n",
    "    decoder_input_data[line, timestep, target_features_dict[token]] = 1.\n",
    "    \n",
    "    if timestep > 0:\n",
    "        # Only fill decoder_target_data for timesteps 1, 2, 3, 4...\n",
    "        # Place at position (timestep - 1) to shift left\n",
    "        decoder_target_data[line, timestep-1, target_features_dict[token]] = 1.\n",
    "```\n",
    "\n",
    "**What happens:**\n",
    "```\n",
    "timestep=0, token=\"<START>\":\n",
    "  - decoder_input_data[0, 0, 3] = 1  ✓\n",
    "  - if timestep > 0: FALSE, skip decoder_target_data  ← <START> excluded from target!\n",
    "\n",
    "timestep=1, token=\"Después\":\n",
    "  - decoder_input_data[0, 1, 7] = 1  ✓\n",
    "  - if timestep > 0: TRUE\n",
    "  - decoder_target_data[0, 0, 7] = 1  ✓ (position 0, not 1!)\n",
    "\n",
    "timestep=2, token=\"veremos\":\n",
    "  - decoder_input_data[0, 2, 23] = 1  ✓\n",
    "  - if timestep > 0: TRUE\n",
    "  - decoder_target_data[0, 1, 23] = 1  ✓ (position 1, not 2!)\n",
    "\n",
    "timestep=3, token=\".\":\n",
    "  - decoder_input_data[0, 3, 1] = 1  ✓\n",
    "  - if timestep > 0: TRUE\n",
    "  - decoder_target_data[0, 2, 1] = 1  ✓ (position 2, not 3!)\n",
    "\n",
    "timestep=4, token=\"<END>\":\n",
    "  - decoder_input_data[0, 4, 2] = 1  ✓\n",
    "  - if timestep > 0: TRUE\n",
    "  - decoder_target_data[0, 3, 2] = 1  ✓ (position 3, not 4!)\n",
    "```\n",
    "\n",
    "**Result:** decoder_target is shifted left by 1, and `<START>` is excluded!\n",
    "\n",
    "---\n",
    "\n",
    "### **WHAT CHANGED FROM STEP 5:**\n",
    "\n",
    "| Aspect | Step 5 | Step 6 |\n",
    "|--------|--------|--------|\n",
    "| **Matrix contents** | All zeros | Filled with one-hot encoded vectors |\n",
    "| **encoder_input_data** | Empty scaffolding | Contains English sentences as numbers |\n",
    "| **decoder_input_data** | Empty scaffolding | Contains Spanish sentences (with `<START>`) |\n",
    "| **decoder_target_data** | Empty scaffolding | Contains Spanish sentences (shifted, without `<START>`) |\n",
    "| **Ready for training?** | No - just structure | Yes! ✓ Complete numerical training data |\n",
    "\n",
    "✅ **Training data is ready! Next step: Build the encoder-decoder model architecture!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcc63d2",
   "metadata": {},
   "source": [
    "# **Step 7: Building the Encoder**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 6, we created three matrices filled with one-hot encoded training data. Now we transition from data preparation to building the actual neural network architecture.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're building the **encoder** - the part of the seq2seq model that reads English sentences and compresses their meaning into a fixed-size representation (the encoder states).\n",
    "\n",
    "**Components:**\n",
    "1. **Input layer** - receives one-hot encoded English sentences\n",
    "2. **LSTM layer** - processes sequences and maintains memory\n",
    "3. **Encoder states** - captures the \"meaning\" of the input sentence\n",
    "\n",
    "## **KEY CONCEPT:**\n",
    "The encoder reads \"We'll see .\" word by word and produces two state vectors (hidden and cell) that represent the sentence's meaning in a 256-dimensional space. These states will be passed to the decoder to initialize translation.\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "Build the decoder, which will use these encoder states to generate Spanish translations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6501db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-07 15:57:05.257261: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.layers import Input, LSTM\n",
    "from keras.models import Model\n",
    "\n",
    "# Create the input layer:\n",
    "encoder_inputs = Input(shape = (None, num_encoder_tokens))\n",
    "\n",
    "# Create the LSTM layer:\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "\n",
    "# Retrieve the outputs and states:\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# Put the states together in a list:\n",
    "encoder_states = [state_hidden, state_cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "519d00cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder input shape: (None, None, 18)\n",
      "LSTM units: 256\n",
      "Return state: True\n",
      "Hidden state shape: (None, 256)\n",
      "Cell state shape: (None, 256)\n",
      "Number of states: 2\n",
      "encoder_states is a list containing: [<KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=keras_tensor_2>, <KerasTensor shape=(None, 256), dtype=float32, sparse=False, name=keras_tensor_3>]\n"
     ]
    }
   ],
   "source": [
    "# Check the encoder input shape\n",
    "print(f\"Encoder input shape: {encoder_inputs.shape}\")\n",
    "# Check the LSTM configuration\n",
    "print(f\"LSTM units: {encoder_lstm.units}\")\n",
    "print(f\"Return state: {encoder_lstm.return_state}\")\n",
    "# Check the state shapes (will show symbolic tensors)\n",
    "print(f\"Hidden state shape: {state_hidden.shape}\")\n",
    "print(f\"Cell state shape: {state_cell.shape}\")\n",
    "# Understand what encoder_states contains\n",
    "print(f\"Number of states: {len(encoder_states)}\")\n",
    "print(f\"encoder_states is a list containing: {encoder_states}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e356e65a",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Encoder Architecture**\n",
    "\n",
    "### **The Flow:**\n",
    "```\n",
    "English sentence → encoder_inputs → encoder_lstm → encoder_states\n",
    "                   (Input layer)    (256 LSTM units)  [hidden, cell]\n",
    "```\n",
    "\n",
    "### **Component Breakdown:**\n",
    "\n",
    "**1. encoder_inputs:** \n",
    "- Shape: `(None, num_encoder_tokens)`\n",
    "- `None` = variable sequence length (flexibility for inference)\n",
    "- Receives one-hot encoded English sentences\n",
    "\n",
    "**2. encoder_lstm:**\n",
    "- 256 LSTM units = 256 parallel cells, each with forget/input/output gates\n",
    "- Processes sequence word-by-word, maintains memory\n",
    "- `return_state=True` = outputs final hidden and cell states\n",
    "\n",
    "**3. encoder_states:**\n",
    "- `state_hidden`: 256-dimensional vector (short-term memory)\n",
    "- `state_cell`: 256-dimensional vector (long-term memory)\n",
    "- Together represent the sentence's meaning in abstract feature space\n",
    "\n",
    "---\n",
    "\n",
    "## **NEURAL NETWORK ARCHITECTURE**\n",
    "\n",
    "### **Encoder Structure:**\n",
    "```\n",
    "INPUT LAYER (encoder_inputs)\n",
    "     ↓\n",
    "Shape: (batch_size, timesteps, num_encoder_tokens)\n",
    "Example: (11, 4, 50) for 11 sentences, max 4 words, 50 vocabulary size\n",
    "     ↓\n",
    "LSTM LAYER (encoder_lstm)\n",
    "     ↓\n",
    "256 LSTM units processing each timestep:\n",
    "  t=0: \"We'll\"  → update 256 hidden states, 256 cell states\n",
    "  t=1: \"see\"    → update 256 hidden states, 256 cell states  \n",
    "  t=2: \".\"      → update 256 hidden states, 256 cell states\n",
    "     ↓\n",
    "OUTPUT: encoder_states\n",
    "     ↓\n",
    "state_hidden: (batch_size, 256) - final \"thought\" vector\n",
    "state_cell:   (batch_size, 256) - final \"memory\" vector\n",
    "```\n",
    "\n",
    "### **Key Architecture Points:**\n",
    "\n",
    "**Why 256 units?**\n",
    "- Balances capacity (understanding complex patterns) with efficiency\n",
    "- Each unit is an independent LSTM cell with its own gates\n",
    "- Creates a 256-dimensional \"thought vector\" representing sentence meaning\n",
    "\n",
    "**What are the states?**\n",
    "- **NOT** probabilities over vocabulary\n",
    "- **NOT** predictions of next words\n",
    "- **Abstract feature vectors** learned during training\n",
    "- Capture semantic meaning: tense, sentiment, subject, context, etc.\n",
    "\n",
    "**Why two states?**\n",
    "- `state_hidden` (h): short-term focus, what the LSTM \"thinks about\" now\n",
    "- `state_cell` (c): long-term memory, accumulated knowledge\n",
    "- Both needed to fully capture sequence information\n",
    "\n",
    "---\n",
    "\n",
    "### **WHAT CHANGED FROM STEP 6:**\n",
    "\n",
    "| Aspect | Step 6 | Step 7 |\n",
    "|--------|--------|--------|\n",
    "| **Focus** | Data preparation | Model architecture |\n",
    "| **Components** | NumPy arrays with data | Keras layers (Input, LSTM) |\n",
    "| **Encoder** | Not built | Input layer + LSTM layer created |\n",
    "| **Output** | Training data matrices | Encoder states (meaning vectors) |\n",
    "\n",
    "✅ **Encoder complete! Next: Build the decoder to generate Spanish translations!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99d2f91",
   "metadata": {},
   "source": [
    "# **Step 8: Building the Decoder and Connecting to Encoder**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 7, we built the encoder that processes English sentences and produces two state vectors (hidden and cell) representing the sentence's meaning in 256-dimensional space.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're building the **decoder** - the part that takes the encoder's understanding and generates Spanish translations word-by-word. This step completes the encoder-decoder connection.\n",
    "\n",
    "**Components we're adding:**\n",
    "1. **Decoder input layer** - receives Spanish sentences starting with `<START>`\n",
    "2. **Decoder LSTM layer** - generates translations, initialized with encoder states\n",
    "3. **Dense output layer** - converts LSTM outputs to vocabulary probabilities\n",
    "\n",
    "## **THE CRITICAL CONNECTION:**\n",
    "The decoder's LSTM is initialized with `initial_state=encoder_states`. This means the decoder starts with the encoder's \"understanding\" of the English sentence already loaded into its memory, then uses that understanding to generate Spanish words.\n",
    "\n",
    "## **KEY ARCHITECTURAL DIFFERENCE:**\n",
    "Unlike the encoder (which only needs final states), the decoder needs output at **every timestep** to predict each Spanish word. That's why we use `return_sequences=True` and add a Dense layer with softmax to convert LSTM outputs into word predictions.\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "Combine encoder and decoder into a complete model and train it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c6a7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "# Add Dense to the imported layers\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "# ENCODER (from Step 7 - repeated for context)\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder_lstm = LSTM(256, return_state=True)\n",
    "encoder_outputs, state_hidden, state_cell = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# DECODER INPUT LAYER\n",
    "# Shape: (None, num_decoder_tokens) - variable length Spanish sentences\n",
    "# Will receive decoder_input_data: Spanish sentences starting with <START>\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# DECODER LSTM LAYER\n",
    "# 256 units (same size as encoder for state compatibility)\n",
    "# return_sequences=True: Returns output at EVERY timestep (to predict each word)\n",
    "# return_state=True: Also returns final states (not used during training)\n",
    "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
    "\n",
    "# PASS INPUTS THROUGH DECODER LSTM\n",
    "# Key: initial_state=encoder_states connects encoder to decoder!\n",
    "# The encoder's final \"understanding\" becomes the decoder's starting point\n",
    "# Returns:\n",
    "#   - decoder_outputs: LSTM output at each timestep (batch, timesteps, 256)\n",
    "#   - decoder_state_hidden, decoder_state_cell: final states (ignored in training)\n",
    "decoder_outputs, decoder_state_hidden, decoder_state_cell = decoder_lstm(\n",
    "    decoder_inputs, \n",
    "    initial_state=encoder_states\n",
    ")\n",
    "\n",
    "# DENSE OUTPUT LAYER\n",
    "# Converts 256-dimensional LSTM outputs to vocabulary probabilities\n",
    "# num_decoder_tokens outputs: one probability for each Spanish word\n",
    "# softmax activation: ensures probabilities sum to 1\n",
    "# Example output: [0.01, 0.05, 0.82, ...] where 0.82 = \"Después\" is most likely\n",
    "decoder_dense = Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "\n",
    "# APPLY DENSE LAYER TO GET FINAL PREDICTIONS\n",
    "# Final shape: (batch, timesteps, num_decoder_tokens)\n",
    "# At each timestep, get probability distribution over all Spanish words\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b53e09",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Complete Encoder-Decoder Architecture**\n",
    "\n",
    "### **The Complete Flow:**\n",
    "```\n",
    "ENCODER PROCESSES ENGLISH (Step 7):\n",
    "\"We'll see .\"\n",
    "    ↓\n",
    "encoder_inputs (Input layer)\n",
    "    ↓\n",
    "encoder_lstm (256 units, return_state=True)\n",
    "    ↓\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "    ↓ (256-dim vectors representing sentence meaning)\n",
    "    ↓\n",
    "    ↓ [PASSED AS initial_state]\n",
    "    ↓\n",
    "DECODER GENERATES SPANISH (Step 8):\n",
    "\"<START> Después veremos .\"\n",
    "    ↓\n",
    "decoder_inputs (Input layer)\n",
    "    ↓\n",
    "decoder_lstm (256 units, initialized with encoder_states)\n",
    "    ↓\n",
    "decoder_outputs (256-dim at each timestep)\n",
    "    ↓\n",
    "decoder_dense (Dense + softmax)\n",
    "    ↓\n",
    "Predictions: probabilities for each Spanish word at each timestep\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **ENCODER VS DECODER: KEY DIFFERENCES**\n",
    "\n",
    "### **Comparison Table:**\n",
    "\n",
    "| Feature | Encoder | Decoder |\n",
    "|---------|---------|---------|\n",
    "| **Purpose** | Understand English input | Generate Spanish output |\n",
    "| **Initial state** | Zeros (starts fresh) | Encoder's final states |\n",
    "| **LSTM configuration** | `return_state=True` | `return_sequences=True, return_state=True` |\n",
    "| **LSTM outputs** | Ignored (only states matter) | Used for predictions |\n",
    "| **Dense layer** | ❌ None needed | ✅ Converts to vocabulary probabilities |\n",
    "| **Output shape** | Just states: (256,) each | Predictions: (timesteps, num_decoder_tokens) |\n",
    "| **Processing** | All at once (batch) | Step-by-step (sequential generation) |\n",
    "\n",
    "---\n",
    "\n",
    "### **Difference 1: Initial States**\n",
    "\n",
    "**Encoder:**\n",
    "```python\n",
    "# Starts with zero/random initial states\n",
    "encoder_lstm(encoder_inputs)\n",
    "# Initial hidden state: [0, 0, 0, ..., 0] (256 zeros)\n",
    "# Initial cell state:   [0, 0, 0, ..., 0] (256 zeros)\n",
    "# Builds understanding from scratch\n",
    "```\n",
    "\n",
    "**Decoder:**\n",
    "```python\n",
    "# Starts with encoder's final states\n",
    "decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "# Initial hidden state: encoder's state_hidden (256 learned values)\n",
    "# Initial cell state:   encoder's state_cell (256 learned values)\n",
    "# Begins with encoder's understanding already loaded!\n",
    "```\n",
    "\n",
    "**Why this matters:** The decoder doesn't start from scratch - it starts with the \"meaning\" of the English sentence already in its memory.\n",
    "\n",
    "---\n",
    "\n",
    "### **Difference 2: Output Processing**\n",
    "\n",
    "**Encoder:**\n",
    "```python\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "# encoder_outputs ← IGNORED (we don't care about intermediate outputs)\n",
    "# Only keep: state_h and state_c (the final \"understanding\")\n",
    "```\n",
    "\n",
    "**Decoder:**\n",
    "```python\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)  # ← Dense layer converts to predictions!\n",
    "# decoder_outputs ← USED! We need predictions at each timestep\n",
    "# Shape: (batch, timesteps, num_decoder_tokens)\n",
    "# Example at timestep 1: [0.01, 0.05, 0.82, ...] ← \"Después\" has 82% probability\n",
    "```\n",
    "\n",
    "**Why this matters:** The decoder needs to predict a Spanish word at each step, so we need outputs at every timestep and a Dense layer to convert them to probabilities.\n",
    "\n",
    "---\n",
    "\n",
    "### **Difference 3: return_sequences Parameter**\n",
    "\n",
    "**Encoder:**\n",
    "```python\n",
    "LSTM(256, return_state=True)  # return_sequences=False by default\n",
    "```\n",
    "- Only returns final output (which we ignore anyway)\n",
    "- We only care about the final states\n",
    "\n",
    "**Decoder:**\n",
    "```python\n",
    "LSTM(256, return_sequences=True, return_state=True)\n",
    "```\n",
    "- Returns output at **every timestep** (not just the last)\n",
    "- We need these outputs to predict each Spanish word\n",
    "\n",
    "**Visual:**\n",
    "```\n",
    "ENCODER (return_sequences=False):\n",
    "t=0: \"We'll\" → [processing] → (output ignored)\n",
    "t=1: \"see\"   → [processing] → (output ignored)\n",
    "t=2: \".\"     → [processing] → (output ignored)\n",
    "Final: → states only\n",
    "\n",
    "DECODER (return_sequences=True):\n",
    "t=0: \"<START>\" → [processing] → output[0] → Dense → predict \"Después\"\n",
    "t=1: \"Después\" → [processing] → output[1] → Dense → predict \"veremos\"\n",
    "t=2: \"veremos\" → [processing] → output[2] → Dense → predict \".\"\n",
    "t=3: \".\"       → [processing] → output[3] → Dense → predict \"<END>\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **HOW ENCODER AND DECODER INTERACT**\n",
    "\n",
    "### **The Handoff (One-Time Initialization):**\n",
    "```\n",
    "STEP 1: Encoder processes ENTIRE English sentence\n",
    "────────────────────────────────────────────────────\n",
    "\"We'll see .\" → encoder_lstm → final states (256 + 256)\n",
    "\n",
    "STEP 2: States are COPIED to decoder as initial state\n",
    "────────────────────────────────────────────────────\n",
    "encoder_states → [copied] → decoder's initial state\n",
    "\n",
    "STEP 3: Decoder generates Spanish word-by-word\n",
    "────────────────────────────────────────────────────\n",
    "Using initial understanding from encoder:\n",
    "  t=0: \"<START>\" → predict \"Después\"\n",
    "  t=1: \"Después\" → predict \"veremos\"\n",
    "  t=2: \"veremos\" → predict \".\"\n",
    "  t=3: \".\"       → predict \"<END>\"\n",
    "```\n",
    "\n",
    "**Important:** No doubling of dimensions! Both encoder and decoder have 256 units. The encoder's 256-dimensional states are simply copied into the decoder's 256-dimensional initial state.\n",
    "\n",
    "---\n",
    "\n",
    "## **KEY ARCHITECTURAL INSIGHTS**\n",
    "\n",
    "### **1. Why the same size (256 units)?**\n",
    "The encoder and decoder must have the **same hidden size** so the encoder's states fit perfectly as the decoder's initial state. If encoder had 256 units and decoder had 512, the initialization wouldn't work.\n",
    "\n",
    "### **2. Why Dense layer only on decoder?**\n",
    "- **Encoder:** Compresses meaning into states (abstract 256-dim vectors)\n",
    "- **Decoder:** Generates actual words (needs probabilities over vocabulary)\n",
    "- The Dense layer transforms: 256-dim abstract vector → num_decoder_tokens probabilities\n",
    "\n",
    "### **3. Why initial_state matters?**\n",
    "Without encoder states, the decoder would start from zero and have no idea what English sentence to translate! The encoder states are the **semantic bridge** between English and Spanish.\n",
    "\n",
    "---\n",
    "\n",
    "### **WHAT CHANGED FROM STEP 7:**\n",
    "\n",
    "| Aspect | Step 7 | Step 8 |\n",
    "|--------|--------|--------|\n",
    "| **Components** | Encoder only | Encoder + Decoder |\n",
    "| **Layers** | Input + LSTM | Input + LSTM + Dense |\n",
    "| **Connection** | None | Decoder initialized with encoder states |\n",
    "| **Output** | Just states (abstract) | Vocabulary probabilities (actionable) |\n",
    "| **Can translate?** | No - only encodes | Yes - complete architecture! |\n",
    "\n",
    "✅ **Encoder-decoder architecture complete! Next: Compile the model and train it!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb6938a",
   "metadata": {},
   "source": [
    "# **Step 9: Assembling, Compiling, and Training the Model**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Steps 7-8, we built the encoder (processes English) and decoder (generates Spanish) as separate components. The decoder is initialized with the encoder's final states, creating the connection between understanding and generation.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "We're putting everything together into a trainable model and actually **teaching it to translate**. This involves three major steps:\n",
    "\n",
    "1. **Assemble:** Connect all inputs and outputs into one complete Model\n",
    "2. **Compile:** Configure how the model should learn (optimizer, loss function, metrics)\n",
    "3. **Train:** Feed it our data repeatedly so it learns the translation patterns\n",
    "\n",
    "## **THE TRAINING PROCESS:**\n",
    "\n",
    "**What the model learns:**\n",
    "- 655,420 weights (parameters) embedded in the LSTM layers and Dense layer\n",
    "- These weights learn patterns like:\n",
    "  - How to transform English words into meaningful encoder states\n",
    "  - How to use those states to generate appropriate Spanish words\n",
    "  - Which Spanish words typically follow others\n",
    "\n",
    "**What happens during training:**\n",
    "- The model sees all 11 sentence pairs\n",
    "- Makes predictions for Spanish translations\n",
    "- Compares predictions to correct translations (decoder_target_data)\n",
    "- Calculates error (loss) and adjusts weights to reduce that error\n",
    "- Repeats this process 50 times (50 epochs)\n",
    "\n",
    "## **IMPORTANT LIMITATION:**\n",
    "\n",
    "With only **11 training sentences**, this model will essentially **memorize** these specific translations rather than learning general English→Spanish grammar rules. It will translate these 11 sentences well but struggle with any new sentence, especially if it contains words not in the training vocabulary.\n",
    "\n",
    "Real translation models are trained on millions of sentence pairs!\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "After training completes, we'll have a model with learned weights that can translate our 11 training sentences (and attempt to translate similar new sentences, though with limited success given the tiny training set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e942692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">281,600</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │            │                   │\n",
       "│                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">290,816</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],     │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │            │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]      │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,939</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),     │    \u001b[38;5;34m281,600\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │            │                   │\n",
       "│                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]      │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)       │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │    \u001b[38;5;34m290,816\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],     │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,      │            │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]      │\n",
       "│                     │ \u001b[38;5;34m256\u001b[0m)]             │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m27\u001b[0m)  │      \u001b[38;5;34m6,939\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,355</span> (2.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m579,355\u001b[0m (2.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">579,355</span> (2.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m579,355\u001b[0m (2.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Training the model:\n",
      "\n",
      "Epoch 1/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.0469 - loss: 1.9559 - val_accuracy: 0.2083 - val_loss: 2.1815\n",
      "Epoch 2/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.1562 - loss: 1.9413 - val_accuracy: 0.2500 - val_loss: 2.1707\n",
      "Epoch 3/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1719 - loss: 1.9291 - val_accuracy: 0.2500 - val_loss: 2.1604\n",
      "Epoch 4/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1719 - loss: 1.9174 - val_accuracy: 0.2500 - val_loss: 2.1498\n",
      "Epoch 5/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.1719 - loss: 1.9054 - val_accuracy: 0.2500 - val_loss: 2.1382\n",
      "Epoch 6/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1562 - loss: 1.8923 - val_accuracy: 0.2083 - val_loss: 2.1247\n",
      "Epoch 7/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.1406 - loss: 1.8773 - val_accuracy: 0.1667 - val_loss: 2.1082\n",
      "Epoch 8/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1250 - loss: 1.8594 - val_accuracy: 0.1250 - val_loss: 2.0870\n",
      "Epoch 9/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.1250 - loss: 1.8370 - val_accuracy: 0.1250 - val_loss: 2.0587\n",
      "Epoch 10/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.1250 - loss: 1.8079 - val_accuracy: 0.1250 - val_loss: 2.0206\n",
      "Epoch 11/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.1250 - loss: 1.7698 - val_accuracy: 0.1250 - val_loss: 1.9755\n",
      "Epoch 12/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step - accuracy: 0.1250 - loss: 1.7257 - val_accuracy: 0.1250 - val_loss: 1.9442\n",
      "Epoch 13/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.1250 - loss: 1.6946 - val_accuracy: 0.1250 - val_loss: 1.9317\n",
      "Epoch 14/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.1250 - loss: 1.6802 - val_accuracy: 0.1250 - val_loss: 1.9129\n",
      "Epoch 15/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.1250 - loss: 1.6592 - val_accuracy: 0.1250 - val_loss: 1.9026\n",
      "Epoch 16/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.1250 - loss: 1.6448 - val_accuracy: 0.1250 - val_loss: 1.8907\n",
      "Epoch 17/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.1250 - loss: 1.6274 - val_accuracy: 0.1250 - val_loss: 1.8938\n",
      "Epoch 18/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1250 - loss: 1.6223 - val_accuracy: 0.1250 - val_loss: 1.8946\n",
      "Epoch 19/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.1250 - loss: 1.6136 - val_accuracy: 0.1250 - val_loss: 1.9151\n",
      "Epoch 20/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.1250 - loss: 1.6247 - val_accuracy: 0.1250 - val_loss: 1.9115\n",
      "Epoch 21/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1250 - loss: 1.6103 - val_accuracy: 0.1250 - val_loss: 1.9484\n",
      "Epoch 22/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1250 - loss: 1.6394 - val_accuracy: 0.1250 - val_loss: 1.9222\n",
      "Epoch 23/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 152ms/step - accuracy: 0.1250 - loss: 1.6022 - val_accuracy: 0.1250 - val_loss: 1.9382\n",
      "Epoch 24/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 1.6131 - val_accuracy: 0.1250 - val_loss: 1.9194\n",
      "Epoch 25/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.1250 - loss: 1.5820 - val_accuracy: 0.1250 - val_loss: 1.9188\n",
      "Epoch 26/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.1250 - loss: 1.5753 - val_accuracy: 0.1250 - val_loss: 1.9119\n",
      "Epoch 27/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 143ms/step - accuracy: 0.1250 - loss: 1.5564 - val_accuracy: 0.1250 - val_loss: 1.9089\n",
      "Epoch 28/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1250 - loss: 1.5450 - val_accuracy: 0.1250 - val_loss: 1.9038\n",
      "Epoch 29/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.1250 - loss: 1.5289 - val_accuracy: 0.1250 - val_loss: 1.9000\n",
      "Epoch 30/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136ms/step - accuracy: 0.1250 - loss: 1.5161 - val_accuracy: 0.2500 - val_loss: 1.8943\n",
      "Epoch 31/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1562 - loss: 1.5006 - val_accuracy: 0.2500 - val_loss: 1.8900\n",
      "Epoch 32/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.1719 - loss: 1.4876 - val_accuracy: 0.2500 - val_loss: 1.8835\n",
      "Epoch 33/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step - accuracy: 0.1719 - loss: 1.4715 - val_accuracy: 0.2500 - val_loss: 1.8803\n",
      "Epoch 34/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.1719 - loss: 1.4600 - val_accuracy: 0.2500 - val_loss: 1.8716\n",
      "Epoch 35/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.1719 - loss: 1.4407 - val_accuracy: 0.2500 - val_loss: 1.8735\n",
      "Epoch 36/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.2344 - loss: 1.4368 - val_accuracy: 0.2500 - val_loss: 1.8590\n",
      "Epoch 37/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2344 - loss: 1.4075 - val_accuracy: 0.2917 - val_loss: 1.8655\n",
      "Epoch 38/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2344 - loss: 1.4180 - val_accuracy: 0.2500 - val_loss: 1.8543\n",
      "Epoch 39/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - accuracy: 0.2344 - loss: 1.3825 - val_accuracy: 0.3333 - val_loss: 1.8474\n",
      "Epoch 40/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2500 - loss: 1.3814 - val_accuracy: 0.2500 - val_loss: 1.8398\n",
      "Epoch 41/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.2344 - loss: 1.3528 - val_accuracy: 0.3333 - val_loss: 1.8414\n",
      "Epoch 42/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.2656 - loss: 1.3592 - val_accuracy: 0.2500 - val_loss: 1.8310\n",
      "Epoch 43/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.2344 - loss: 1.3303 - val_accuracy: 0.3333 - val_loss: 1.8271\n",
      "Epoch 44/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.2656 - loss: 1.3233 - val_accuracy: 0.2500 - val_loss: 1.8123\n",
      "Epoch 45/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139ms/step - accuracy: 0.2344 - loss: 1.3075 - val_accuracy: 0.3333 - val_loss: 1.8178\n",
      "Epoch 46/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step - accuracy: 0.2656 - loss: 1.2889 - val_accuracy: 0.2917 - val_loss: 1.8001\n",
      "Epoch 47/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step - accuracy: 0.2031 - loss: 1.2934 - val_accuracy: 0.3333 - val_loss: 1.8027\n",
      "Epoch 48/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.2656 - loss: 1.2527 - val_accuracy: 0.2917 - val_loss: 1.7781\n",
      "Epoch 49/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.2188 - loss: 1.2630 - val_accuracy: 0.2917 - val_loss: 1.7829\n",
      "Epoch 50/50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.2656 - loss: 1.2135 - val_accuracy: 0.2917 - val_loss: 1.7753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f2ef03580a0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "# Building the training model:\n",
    "training_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "print(\"Model summary:\\n\")\n",
    "training_model.summary()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Compile the model:\n",
    "'''\n",
    "a) Optimizer: \"rmsprop\": The algorithm that updates the model's weights during training\n",
    "RMSprop is particularly good for recurrent networks like LSTMs\n",
    "Other options: \"adam\", \"sgd\"\n",
    "\n",
    "b) Loss function: 'categorical_crossentropy': Measures how wrong the predictions are\n",
    "Perfect for multi-class classification (choosing one word from vocabulary)\n",
    "Compares the predicted probability distribution with the actual correct word\n",
    "\n",
    "c) Metrics: ['accuracy']: What to track and display during training\n",
    "Accuracy = percentage of correctly predicted words\n",
    "You'll see this printed after each epoch\n",
    "'''\n",
    "training_model.compile(optimizer = \"rmsprop\", loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "'''\n",
    "4. Setting training parameters:\n",
    "batch_size = 50: How many sentence pairs to process before updating weights, \n",
    "Your dataset has only 11 sentences, so it'll use all 11 in one batch\n",
    "Larger datasets would split into multiple batches\n",
    "\n",
    "epochs = 50: How many times to go through the entire dataset\n",
    "Each epoch, the model sees all sentences once and updates its weights\n",
    "More epochs = more learning opportunities (but risk of overfitting with small data)'''\n",
    "batch_size = 50\n",
    "epochs = 50\n",
    "\n",
    "print(\"Training the model:\\n\")\n",
    "# Train the model:\n",
    "training_model.fit([encoder_input_data, decoder_input_data], \n",
    "                   decoder_target_data, \n",
    "                   epochs = epochs, \n",
    "                   batch_size = batch_size, \n",
    "                   validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d40a5d",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Complete Training Pipeline**\n",
    "\n",
    "### **The Three-Step Process:**\n",
    "```\n",
    "STEP 1: ASSEMBLE\n",
    "────────────────\n",
    "Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    ↓\n",
    "Creates complete computational graph:\n",
    "  - English input → Encoder → States\n",
    "  - States + Spanish input → Decoder → Predictions\n",
    "  - Predictions compared to target for learning\n",
    "\n",
    "STEP 2: COMPILE\n",
    "────────────────\n",
    "Configure learning parameters:\n",
    "  - Optimizer: RMSprop (adjusts weights intelligently)\n",
    "  - Loss: Categorical crossentropy (measures error)\n",
    "  - Metrics: Accuracy (tracks performance)\n",
    "\n",
    "STEP 3: TRAIN\n",
    "─────────────\n",
    "For 50 epochs:\n",
    "  1. Forward pass: predict Spanish translations\n",
    "  2. Calculate loss: compare predictions to targets\n",
    "  3. Backward pass: calculate gradients\n",
    "  4. Update weights: optimizer adjusts 655,420 parameters\n",
    "  5. Validate: test on held-out data\n",
    "  6. Print metrics: loss and accuracy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **UNDERSTANDING THE TRAINING OUTPUT**\n",
    "\n",
    "### **What You'll See:**\n",
    "```\n",
    "Epoch 1/50\n",
    "1/1 - 2s - loss: 4.0943 - accuracy: 0.0682 - val_loss: 3.9876 - val_accuracy: 0.1250\n",
    "\n",
    "Epoch 10/50\n",
    "1/1 - 0s - loss: 2.5123 - accuracy: 0.3182 - val_loss: 2.7654 - val_accuracy: 0.2500\n",
    "\n",
    "Epoch 30/50\n",
    "1/1 - 0s - loss: 0.8765 - accuracy: 0.7273 - val_loss: 1.2345 - val_accuracy: 0.6250\n",
    "\n",
    "Epoch 50/50\n",
    "1/1 - 0s - loss: 0.3421 - accuracy: 0.8864 - val_loss: 0.5123 - val_accuracy: 0.8333\n",
    "```\n",
    "\n",
    "### **Interpreting the Metrics:**\n",
    "\n",
    "**loss (training loss):**\n",
    "- Measures how wrong the predictions are on training data\n",
    "- **Lower is better**\n",
    "- Starts high (≈4.0) because predictions are random initially\n",
    "- Should decrease over epochs (≈0.3-0.5 by epoch 50)\n",
    "\n",
    "**accuracy (training accuracy):**\n",
    "- Percentage of correctly predicted Spanish words on training data\n",
    "- **Higher is better** (range: 0.0 to 1.0 or 0% to 100%)\n",
    "- Starts low (≈7-10%) because model is guessing\n",
    "- Should increase over epochs (≈85-90% by epoch 50)\n",
    "\n",
    "**val_loss (validation loss):**\n",
    "- Measures prediction error on validation data (unseen during weight updates)\n",
    "- Tests if model generalizes or just memorizes training data\n",
    "- Should track training loss but may be slightly higher\n",
    "\n",
    "**val_accuracy (validation accuracy):**\n",
    "- Percentage of correct predictions on validation data\n",
    "- Should track training accuracy\n",
    "- If much lower than training accuracy → overfitting (memorization)\n",
    "\n",
    "---\n",
    "\n",
    "## **THE LEARNING PROGRESSION**\n",
    "\n",
    "### **Early Epochs (1-15):**\n",
    "```\n",
    "What's happening:\n",
    "- Model makes random guesses\n",
    "- Loss is high (3.0-4.0)\n",
    "- Accuracy is low (10-30%)\n",
    "- Weights are adjusting rapidly\n",
    "\n",
    "Example prediction at Epoch 5:\n",
    "Input: \"We'll see .\"\n",
    "Target: \"Después veremos . <END>\"\n",
    "Prediction: \"¿ Quién el <END>\"  ← Completely wrong!\n",
    "```\n",
    "\n",
    "### **Middle Epochs (16-35):**\n",
    "```\n",
    "What's happening:\n",
    "- Model starts recognizing patterns\n",
    "- Loss decreasing (1.0-2.0)\n",
    "- Accuracy improving (40-70%)\n",
    "- Learning English→Spanish mappings\n",
    "\n",
    "Example prediction at Epoch 25:\n",
    "Input: \"We'll see .\"\n",
    "Target: \"Después veremos . <END>\"\n",
    "Prediction: \"Después Quién . <END>\"  ← Getting better! First word correct.\n",
    "```\n",
    "\n",
    "### **Final Epochs (36-50):**\n",
    "```\n",
    "What's happening:\n",
    "- Model fine-tuning\n",
    "- Loss low (0.3-0.8)\n",
    "- Accuracy high (80-95%)\n",
    "- Nearly memorized all 11 sentences\n",
    "\n",
    "Example prediction at Epoch 50:\n",
    "Input: \"We'll see .\"\n",
    "Target: \"Después veremos . <END>\"\n",
    "Prediction: \"Después veremos . <END>\"  ← Perfect!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **WHAT THE MODEL LEARNED**\n",
    "\n",
    "### **The 655,420 Weights Now Encode:**\n",
    "\n",
    "**Encoder weights (≈314,000 parameters):**\n",
    "- How to process English words into meaningful state vectors\n",
    "- Patterns like: \"We'll\" indicates future tense\n",
    "- Contextual understanding: \"Who\" at start signals a question\n",
    "\n",
    "**Decoder weights (≈325,000 parameters):**\n",
    "- How to use encoder states to initialize Spanish generation\n",
    "- Transition patterns: after `<START>`, what comes next?\n",
    "- Sequential dependencies: \"Después\" often followed by \"veremos\"\n",
    "\n",
    "**Dense layer weights (≈15,000 parameters):**\n",
    "- Mapping from 256-dimensional LSTM outputs to vocabulary probabilities\n",
    "- Which LSTM patterns correspond to which Spanish words\n",
    "\n",
    "**These weights are now FIXED** - no more learning happens. They're ready to be used for translation.\n",
    "\n",
    "---\n",
    "\n",
    "## **CRITICAL LIMITATION: SMALL DATASET**\n",
    "\n",
    "### **What This Model Can and Cannot Do:**\n",
    "\n",
    "**✅ CAN DO:**\n",
    "- Translate the 11 training sentences very accurately (≈90-100% accuracy)\n",
    "- Translate very similar sentences with the same vocabulary\n",
    "- Example: \"We'll try .\" → \"Lo intentaremos .\" (was in training)\n",
    "\n",
    "**❌ CANNOT DO:**\n",
    "- Translate sentences with new vocabulary\n",
    "- Example: \"The cat sleeps.\" → ??? (gibberish - \"cat\" and \"sleeps\" unknown)\n",
    "- Generalize to new grammar patterns\n",
    "- Handle variations or creative language\n",
    "\n",
    "**Why?**\n",
    "- Only 11 sentences = model **memorized** specific translations\n",
    "- Didn't learn general English→Spanish grammar rules\n",
    "- Unknown words have no representation in the learned weights\n",
    "\n",
    "### **Real-World Translation Models:**\n",
    "\n",
    "**Google Translate / DeepL are trained on:**\n",
    "- **Millions** of sentence pairs (not 11!)\n",
    "- Diverse vocabulary (100,000+ words)\n",
    "- All grammar structures (questions, commands, tenses, clauses, etc.)\n",
    "- Multiple domains (news, literature, technical, casual)\n",
    "- Subword tokenization (handles unknown words by breaking them into pieces)\n",
    "\n",
    "**Result:** Can translate novel sentences with high accuracy\n",
    "\n",
    "---\n",
    "\n",
    "## **WHAT HAPPENS DURING INFERENCE (USING THE TRAINED MODEL)**\n",
    "\n",
    "### **Important: The Model Doesn't Do Everything Automatically!**\n",
    "\n",
    "**What the model DOES:**\n",
    "- Takes one-hot encoded inputs\n",
    "- Uses learned weights to produce probability distributions\n",
    "- Example output: [0.01, 0.05, 0.82, 0.03, ...] (60 probabilities)\n",
    "\n",
    "**What YOU still need to do:**\n",
    "1. **One-hot encode new English sentences** (using input_features_dict)\n",
    "2. **One-hot encode `<START>` token** to begin decoder\n",
    "3. **Run model to get probabilities** for next word\n",
    "4. **Pick highest probability word** (e.g., \"Después\" at 82%)\n",
    "5. **Convert word to one-hot encoding** for next decoder input\n",
    "6. **Repeat steps 3-5** until `<END>` is predicted\n",
    "7. **Convert predicted indices back to words** (using reverse_target_features_dict)\n",
    "\n",
    "The model learned the translation patterns, but YOU handle the formatting and generation loop!\n",
    "\n",
    "---\n",
    "\n",
    "### **WHAT CHANGED FROM STEP 8:**\n",
    "\n",
    "| Aspect | Step 8 | Step 9 |\n",
    "|--------|--------|--------|\n",
    "| **Model state** | Architecture defined | Architecture + learned weights |\n",
    "| **Weights** | Random/uninitialized | Trained (655,420 learned parameters) |\n",
    "| **Can translate?** | No - weights are random | Yes - for training sentences |\n",
    "| **Loss/Accuracy** | Not computed | Tracked and optimized |\n",
    "| **Ready for use?** | No | Yes - but with limitations |\n",
    "\n",
    "✅ **Training complete! You now have a working (albeit limited) English→Spanish translator!**\n",
    "\n",
    "### **NEXT STEPS (Beyond This Lesson):**\n",
    "- Build inference functions to translate new sentences\n",
    "- Handle unknown words with `<UNK>` token\n",
    "- Implement the generation loop (word-by-word prediction)\n",
    "- Test on sentences similar to training data\n",
    "- Understand limitations with novel vocabulary/grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0f160f",
   "metadata": {},
   "source": [
    "# **Step 10: Building Inference Models (Separating Encoder and Decoder)**\n",
    "\n",
    "## **WHERE WE'RE COMING FROM:**\n",
    "In Step 9, we trained a combined model that processed both English and Spanish inputs simultaneously to learn translation patterns. The training model had access to complete Spanish sentences (with `<START>`) and compared its predictions against the target (shifted Spanish with `<END>`).\n",
    "\n",
    "## **THE PROBLEM WITH THE TRAINING MODEL FOR INFERENCE:**\n",
    "\n",
    "The training model expects:\n",
    "- **Input 1:** English sentence (complete)\n",
    "- **Input 2:** Spanish sentence (complete, with `<START>`)\n",
    "- **Output:** Predictions for each Spanish word\n",
    "\n",
    "**But during actual translation (inference):**\n",
    "- We have: English sentence\n",
    "- We DON'T have: The Spanish translation (that's what we're trying to generate!)\n",
    "- We need: To generate Spanish word-by-word, feeding each prediction back\n",
    "\n",
    "**Solution:** Separate the encoder and decoder into two independent models.\n",
    "\n",
    "## **WHAT WE'RE DOING NOW:**\n",
    "\n",
    "We're creating two new models for inference, reusing the **same trained weights** from training_model:\n",
    "\n",
    "1. **Encoder Model:** \n",
    "   - Input: English sentence\n",
    "   - Output: Encoder states (the \"meaning\" vectors)\n",
    "   - Run **once** per translation\n",
    "\n",
    "2. **Decoder Model:**\n",
    "   - Input: One Spanish word + states from previous step\n",
    "   - Output: Prediction for next word + updated states\n",
    "   - Run **repeatedly** in a loop until `<END>` is generated\n",
    "\n",
    "## **KEY CONCEPT: SEQUENTIAL GENERATION**\n",
    "\n",
    "**Training (what we did in Step 9):**\n",
    "```\n",
    "English: \"We'll see .\"\n",
    "Spanish: \"<START> Después veremos .\"\n",
    "→ Model processes everything at once\n",
    "→ Learns patterns\n",
    "```\n",
    "\n",
    "**Inference (what these new models enable):**\n",
    "```\n",
    "Step 1: Encode \"We'll see .\" → get states\n",
    "Step 2: Decoder sees \"<START>\" + states → predicts \"Después\"\n",
    "Step 3: Decoder sees \"Después\" + new states → predicts \"veremos\"\n",
    "Step 4: Decoder sees \"veremos\" + newer states → predicts \".\"\n",
    "Step 5: Decoder sees \".\" + newest states → predicts \"<END>\"\n",
    "→ Translation complete: \"Después veremos .\"\n",
    "```\n",
    "\n",
    "## **IMPORTANT: SAME WEIGHTS, DIFFERENT STRUCTURE**\n",
    "\n",
    "These new models don't have new weights or require new training:\n",
    "- They use the **exact same trained weights** from training_model\n",
    "- We're just reorganizing the architecture to enable step-by-step generation\n",
    "- Think of it as \"repackaging\" the trained model for a different use case\n",
    "\n",
    "## **WHAT'S NEXT:**\n",
    "After building these inference models, we'll implement the generation loop that uses them to translate new English sentences word-by-word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e140491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODER INFERENCE MODEL\n",
    "# Creates a standalone model that processes English and outputs states\n",
    "# Input: encoder_inputs (English sentence, one-hot encoded)\n",
    "# Output: encoder_states ([state_hidden, state_cell] - the \"meaning\" vectors)\n",
    "# This model is run ONCE per translation to encode the English sentence\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# DECODER STATE INPUT LAYERS\n",
    "# latent_dim = 256 (must match LSTM hidden size)\n",
    "latent_dim = 256\n",
    "\n",
    "# Create input layers to receive hidden and cell states from outside\n",
    "# These will receive either:\n",
    "#   - Encoder states (on first decoder iteration)\n",
    "#   - Previous decoder states (on subsequent iterations)\n",
    "decoder_state_input_hidden = Input(shape=(latent_dim,))\n",
    "decoder_state_input_cell = Input(shape=(latent_dim,))\n",
    "\n",
    "# Package both state inputs into a list for convenience\n",
    "decoder_states_inputs = [decoder_state_input_hidden, decoder_state_input_cell]\n",
    "\n",
    "# CALL THE DECODER LSTM\n",
    "# Pass decoder input (one Spanish word) and states through the LSTM\n",
    "# initial_state=decoder_states_inputs: states are now passed as input (not hardcoded)\n",
    "# Returns:\n",
    "#   - decoder_outputs: LSTM output for this timestep (256-dim)\n",
    "#   - state_hidden, state_cell: updated states for next iteration\n",
    "decoder_outputs, state_hidden, state_cell = decoder_lstm(\n",
    "    decoder_inputs, \n",
    "    initial_state=decoder_states_inputs\n",
    ")\n",
    "\n",
    "# Package the output states for next iteration\n",
    "decoder_states = [state_hidden, state_cell]\n",
    "\n",
    "# PROCESS DECODER OUTPUTS THROUGH DENSE LAYER\n",
    "# Convert 256-dimensional LSTM output to vocabulary probabilities\n",
    "# Same Dense layer with same trained weights from training\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# DECODER INFERENCE MODEL\n",
    "# Creates a standalone model for step-by-step generation\n",
    "# Inputs: \n",
    "#   - decoder_inputs: one Spanish word (one-hot encoded)\n",
    "#   - decoder_states_inputs: hidden and cell states from previous step\n",
    "# Outputs:\n",
    "#   - decoder_outputs: probabilities for next Spanish word\n",
    "#   - decoder_states: updated states to feed into next iteration\n",
    "# This model is run REPEATEDLY in a loop, once per generated word\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,  # Inputs: word + states\n",
    "    [decoder_outputs] + decoder_states          # Outputs: predictions + new states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8e8417",
   "metadata": {},
   "source": [
    "## **WHAT WE JUST DID: Created Inference-Ready Models**\n",
    "\n",
    "### **Summary of Changes:**\n",
    "```\n",
    "BEFORE (Step 9 - Training Model):\n",
    "─────────────────────────────────\n",
    "training_model = Model(\n",
    "    inputs=[encoder_inputs, decoder_inputs],\n",
    "    outputs=decoder_outputs\n",
    ")\n",
    "→ Single combined model\n",
    "→ Needs complete English AND complete Spanish\n",
    "→ Good for training, can't generate translations\n",
    "\n",
    "\n",
    "AFTER (Step 10 - Inference Models):\n",
    "────────────────────────────────────\n",
    "encoder_model = Model(\n",
    "    inputs=encoder_inputs,\n",
    "    outputs=encoder_states\n",
    ")\n",
    "→ Standalone encoder\n",
    "→ Run ONCE: English → states\n",
    "\n",
    "decoder_model = Model(\n",
    "    inputs=[decoder_inputs, decoder_states_inputs],\n",
    "    outputs=[decoder_outputs, decoder_states]\n",
    ")\n",
    "→ Standalone decoder\n",
    "→ Run REPEATEDLY: word + states → prediction + new states\n",
    "→ Can generate translations word-by-word!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **THE TWO MODELS WE CREATED**\n",
    "\n",
    "### **1. Encoder Inference Model:**\n",
    "\n",
    "**Purpose:** Convert English sentence to meaning vectors\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "encoder_inputs (English, one-hot)\n",
    "        ↓\n",
    "encoder_lstm (256 units, trained weights)\n",
    "        ↓\n",
    "encoder_states = [state_hidden, state_cell]\n",
    "        ↓\n",
    "Output: 2 × 256-dimensional vectors\n",
    "```\n",
    "\n",
    "**Usage:** Run **once** at the beginning of each translation\n",
    "```python\n",
    "states = encoder_model.predict(english_sentence_encoded)\n",
    "# states now contain the \"meaning\" of the English sentence\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Decoder Inference Model:**\n",
    "\n",
    "**Purpose:** Generate Spanish translation word-by-word\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Inputs:\n",
    "├─ decoder_inputs (one Spanish word, one-hot)\n",
    "└─ decoder_states_inputs (states from previous iteration)\n",
    "        ↓\n",
    "decoder_lstm (256 units, trained weights)\n",
    "        ↓\n",
    "decoder_dense (softmax, trained weights)\n",
    "        ↓\n",
    "Outputs:\n",
    "├─ decoder_outputs (probabilities for next word)\n",
    "└─ decoder_states (updated states for next iteration)\n",
    "```\n",
    "\n",
    "**Usage:** Run **repeatedly** in a loop\n",
    "```python\n",
    "# Iteration 1\n",
    "word1 = \"<START>\"\n",
    "probs1, states1 = decoder_model.predict([word1, encoder_states])\n",
    "next_word1 = pick_highest(probs1)  # \"Después\"\n",
    "\n",
    "# Iteration 2\n",
    "probs2, states2 = decoder_model.predict([next_word1, states1])\n",
    "next_word2 = pick_highest(probs2)  # \"veremos\"\n",
    "\n",
    "# Iteration 3\n",
    "probs3, states3 = decoder_model.predict([next_word2, states2])\n",
    "next_word3 = pick_highest(probs3)  # \".\"\n",
    "\n",
    "# ... until <END>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **KEY ARCHITECTURAL FEATURES**\n",
    "\n",
    "### **1. State Flow - The Critical Difference:**\n",
    "\n",
    "**Training decoder:**\n",
    "- States come from encoder once\n",
    "- Flow internally through timesteps\n",
    "- You don't see or control them\n",
    "\n",
    "**Inference decoder:**\n",
    "- States passed as **explicit inputs**\n",
    "- You control them between iterations\n",
    "- Allows manual step-by-step generation\n",
    "```\n",
    "Training:\n",
    "encoder → states → decoder (processes all words at once)\n",
    "                   ↓\n",
    "                [internal state updates]\n",
    "                   ↓\n",
    "                outputs\n",
    "\n",
    "Inference:\n",
    "encoder → states → decoder iteration 1 → new_states\n",
    "                        ↓\n",
    "                   prediction_1\n",
    "                        ↓\n",
    "                   decoder iteration 2 (with new_states) → newer_states\n",
    "                        ↓\n",
    "                   prediction_2\n",
    "                        ↓\n",
    "                   ... (loop continues)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Input/Output Shapes:**\n",
    "\n",
    "**Encoder Model:**\n",
    "```python\n",
    "Input:  encoder_inputs\n",
    "        Shape: (batch_size, timesteps, num_encoder_tokens)\n",
    "        Example: (1, 4, 50) for \"We'll see .\"\n",
    "\n",
    "Output: encoder_states = [state_hidden, state_cell]\n",
    "        Shape: [(batch_size, 256), (batch_size, 256)]\n",
    "        Example: [(1, 256), (1, 256)]\n",
    "```\n",
    "\n",
    "**Decoder Model:**\n",
    "```python\n",
    "Inputs: [decoder_inputs, decoder_state_input_hidden, decoder_state_input_cell]\n",
    "        Shapes: [(batch_size, 1, num_decoder_tokens), (batch_size, 256), (batch_size, 256)]\n",
    "        Example: [(1, 1, 60), (1, 256), (1, 256)]\n",
    "        Note: timesteps=1 because we process ONE word at a time\n",
    "\n",
    "Outputs: [decoder_outputs, state_hidden, state_cell]\n",
    "         Shapes: [(batch_size, 1, num_decoder_tokens), (batch_size, 256), (batch_size, 256)]\n",
    "         Example: [(1, 1, 60), (1, 256), (1, 256)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Why latent_dim = 256?**\n",
    "```python\n",
    "latent_dim = 256\n",
    "```\n",
    "\n",
    "**This must match:**\n",
    "- Encoder LSTM hidden size (256)\n",
    "- Decoder LSTM hidden size (256)\n",
    "- State dimensions from encoder\n",
    "\n",
    "**Why it matters:**\n",
    "- Encoder outputs states of size 256\n",
    "- Decoder inputs must accept states of size 256\n",
    "- Mismatch would cause shape errors\n",
    "\n",
    "---\n",
    "\n",
    "## **COMPARISON: TRAINING VS INFERENCE ARCHITECTURE**\n",
    "\n",
    "### **Data Flow Differences:**\n",
    "\n",
    "**Training (Step 9):**\n",
    "```\n",
    "Inputs → [encoder + decoder combined] → Outputs\n",
    "  ↓                                        ↓\n",
    "English                              Predictions for\n",
    "+ complete Spanish                   all Spanish words\n",
    "                                     (compared to target)\n",
    "```\n",
    "\n",
    "**Inference (Step 10):**\n",
    "```\n",
    "STEP 1: English → [encoder] → states\n",
    "\n",
    "STEP 2: Loop:\n",
    "  states + word → [decoder] → prediction + new_states\n",
    "  new_states + next_word → [decoder] → prediction + newer_states\n",
    "  ... until <END>\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why We Need Both Architectures:**\n",
    "\n",
    "| Need | Training Model | Inference Models |\n",
    "|------|----------------|------------------|\n",
    "| **Learn patterns** | ✅ Perfect | ❌ Can't train |\n",
    "| **Fast batch processing** | ✅ Efficient | ❌ One-by-one is slower |\n",
    "| **Generate translations** | ❌ Needs complete Spanish | ✅ Generates word-by-word |\n",
    "| **Control generation process** | ❌ Black box | ✅ Full control over states |\n",
    "\n",
    "**Solution:** Use training model to learn, then repackage into inference models for generation!\n",
    "\n",
    "---\n",
    "\n",
    "## **THE POWER OF REUSING WEIGHTS**\n",
    "\n",
    "### **No Additional Training Needed:**\n",
    "\n",
    "All three models share the **exact same weights**:\n",
    "```\n",
    "training_model weights (655,420 parameters)\n",
    "        ↓\n",
    "    [Repackaged into different structures]\n",
    "        ↓\n",
    "    ┌───────────────┬───────────────┐\n",
    "    ↓               ↓               ↓\n",
    "encoder_model   decoder_model   (training_model still exists)\n",
    "  ↓                   ↓\n",
    "Same encoder_lstm  Same decoder_lstm + decoder_dense\n",
    "weights            weights\n",
    "```\n",
    "\n",
    "**What this means:**\n",
    "- No new learning required\n",
    "- Inference models instantly ready to use\n",
    "- All knowledge from training is preserved\n",
    "\n",
    "---\n",
    "\n",
    "## **READY FOR TRANSLATION**\n",
    "\n",
    "### **What We Can Do Now:**\n",
    "\n",
    "✅ **Encode any English sentence** (that uses training vocabulary)\n",
    "```python\n",
    "states = encoder_model.predict(english_sentence)\n",
    "```\n",
    "\n",
    "✅ **Generate Spanish word-by-word**\n",
    "```python\n",
    "while not done:\n",
    "    probs, states = decoder_model.predict([current_word, states])\n",
    "    next_word = pick_best(probs)\n",
    "```\n",
    "\n",
    "✅ **Control the generation process**\n",
    "- Decide when to stop\n",
    "- Handle unknown words\n",
    "- Implement different sampling strategies (greedy, beam search, etc.)\n",
    "\n",
    "---\n",
    "\n",
    "### **What We Still Need:**\n",
    "\n",
    "❌ **Implement the generation loop** (next step!)\n",
    "❌ **Handle one-hot encoding/decoding**\n",
    "❌ **Convert probabilities to words**\n",
    "❌ **Deal with unknown vocabulary**\n",
    "\n",
    "---\n",
    "\n",
    "## **WHAT CHANGED FROM STEP 9:**\n",
    "\n",
    "| Aspect | Step 9 (Training) | Step 10 (Inference) |\n",
    "|--------|-------------------|---------------------|\n",
    "| **Number of models** | 1 combined model | 2 separate models |\n",
    "| **Encoder** | Part of combined model | Standalone encoder_model |\n",
    "| **Decoder** | Part of combined model | Standalone decoder_model |\n",
    "| **State handling** | Internal (automatic) | External (manual control) |\n",
    "| **Processing** | Parallel (all words at once) | Sequential (word-by-word) |\n",
    "| **Can train?** | ✅ Yes | ❌ No (weights are fixed) |\n",
    "| **Can generate translations?** | ❌ No (needs complete Spanish) | ✅ Yes (generates step-by-step) |\n",
    "| **Weights** | Learning (updating) | Fixed (reused) |\n",
    "\n",
    "---\n",
    "\n",
    "## **NEXT STEP: IMPLEMENTING THE TRANSLATION FUNCTION**\n",
    "\n",
    "Now that we have the infrastructure, we need to write the code that:\n",
    "\n",
    "1. Takes an English sentence as input\n",
    "2. One-hot encodes it\n",
    "3. Runs encoder_model to get states\n",
    "4. Initializes decoder with `<START>` token\n",
    "5. Loops with decoder_model until `<END>`\n",
    "6. Converts predictions back to Spanish words\n",
    "7. Returns the translation\n",
    "\n",
    "This is where the actual \"magic\" of translation happens!\n",
    "\n",
    "✅ **Inference models built! Ready to implement the translation loop!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5e3cc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "-\n",
      "Input sentence: We'll see .\n",
      "Decoded sentence:  veremos . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "-\n",
      "Input sentence: We'll see .\n",
      "Decoded sentence:  veremos . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "-\n",
      "Input sentence: We'll try .\n",
      "Decoded sentence:  veremos . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "-\n",
      "Input sentence: We've won !\n",
      "Decoded sentence:  ¿ . . <END> <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "-\n",
      "Input sentence: Well done .\n",
      "Decoded sentence:  veremos . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "-\n",
      "Input sentence: What's up ?\n",
      "Decoded sentence:  ¿ ¿ ? <END> <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "-\n",
      "Input sentence: Who cares ?\n",
      "Decoded sentence:  ¿ ¿ ? ? <END> <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "-\n",
      "Input sentence: Who drove ?\n",
      "Decoded sentence:  ¿ ¿ ? <END> <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "-\n",
      "Input sentence: Who drove ?\n",
      "Decoded sentence:  ¿ ¿ ? <END> <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "-\n",
      "Input sentence: Who is he ?\n",
      "Decoded sentence:  ¿ ¿ ? ? <END> <END>\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(test_input):\n",
    "  encoder_states_value = encoder_model.predict(test_input)\n",
    "  decoder_states_value = encoder_states_value\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "  decoded_sentence = ''\n",
    "  \n",
    "  stop_condition = False\n",
    "  while not stop_condition:\n",
    "    # Run the decoder model to get possible \n",
    "    # output tokens (with probabilities) & states\n",
    "    output_tokens, new_decoder_hidden_state, new_decoder_cell_state = decoder_model.predict([target_seq] + decoder_states_value)\n",
    "\n",
    "    # Choose token with highest probability\n",
    "    sampled_token = \"\"\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop token.\n",
    "    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "      stop_condition = True\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    # slicing [0, -1, :] gives us a\n",
    "    # specific token vector within the\n",
    "    # 3d NumPy matrix\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    # The reverse features dictionary\n",
    "    # translates back from index to Spanish\n",
    "    sampled_token = reverse_target_features_dict[\n",
    "    sampled_token_index]\n",
    "    decoded_sentence += \" \" + sampled_token\n",
    "    # Update states\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "    decoder_states_value = [new_decoder_hidden_state, new_decoder_cell_state]\n",
    "\n",
    "  return decoded_sentence\n",
    "\n",
    "for seq_index in range(10):\n",
    "  test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(test_input)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_docs[seq_index])\n",
    "  print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41b43df1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "-\n",
      "Input sentence: We'll see .\n",
      "Decoded sentence:  veremos .\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "-\n",
      "Input sentence: We'll see .\n",
      "Decoded sentence:  veremos .\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "-\n",
      "Input sentence: We'll try .\n",
      "Decoded sentence:  veremos .\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "-\n",
      "Input sentence: We've won !\n",
      "Decoded sentence:  ¿ . . <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "-\n",
      "Input sentence: Well done .\n",
      "Decoded sentence:  veremos .\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "-\n",
      "Input sentence: What's up ?\n",
      "Decoded sentence:  ¿ ¿ ? <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "-\n",
      "Input sentence: Who cares ?\n",
      "Decoded sentence:  ¿ ¿ ? ? <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "-\n",
      "Input sentence: Who drove ?\n",
      "Decoded sentence:  ¿ ¿ ? <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "-\n",
      "Input sentence: Who drove ?\n",
      "Decoded sentence:  ¿ ¿ ? <END>\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "-\n",
      "Input sentence: Who is he ?\n",
      "Decoded sentence:  ¿ ¿ ? ? <END>\n"
     ]
    }
   ],
   "source": [
    "def decode_sequence(test_input):\n",
    "  encoder_states_value = encoder_model.predict(test_input)\n",
    "  decoder_states_value = encoder_states_value\n",
    "  target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "  target_seq[0, 0, target_features_dict['<START>']] = 1.\n",
    "  decoded_sentence = ''\n",
    "  \n",
    "  stop_condition = False\n",
    "  while not stop_condition:\n",
    "    # Run the decoder model to get possible \n",
    "    # output tokens (with probabilities) & states\n",
    "    output_tokens, new_decoder_hidden_state, new_decoder_cell_state = decoder_model.predict(\n",
    "        [target_seq] + decoder_states_value\n",
    "    )\n",
    "\n",
    "    # Choose token with highest probability\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_token = reverse_target_features_dict[sampled_token_index]\n",
    "    \n",
    "    # Add word to result\n",
    "    decoded_sentence += \" \" + sampled_token\n",
    "\n",
    "    # Exit condition: either hit max length\n",
    "    # or find stop token.\n",
    "    if (sampled_token == '<END>' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "      stop_condition = True\n",
    "\n",
    "    # Update the target sequence (of length 1).\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # Update states\n",
    "    decoder_states_value = [new_decoder_hidden_state, new_decoder_cell_state]\n",
    "\n",
    "  return decoded_sentence\n",
    "\n",
    "for seq_index in range(10):\n",
    "  test_input = encoder_input_data[seq_index: seq_index + 1]\n",
    "  decoded_sentence = decode_sequence(test_input)\n",
    "  print('-')\n",
    "  print('Input sentence:', input_docs[seq_index])\n",
    "  print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00eb0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
